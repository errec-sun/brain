{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Февральский курс. Разбор домашнего задания #8. Аудио",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/errec-sun/brain/blob/master/8_ghbvth_%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D1%8F_8_%D0%90%D1%83%D0%B4%D0%B8%D0%BE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWiCMHe2LPU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Подключаем библиотеки\n",
        "from google.colab import files #Загрузка файлов\n",
        "from tensorflow.keras import utils #Для to_categorical\n",
        "import os #Работа с папками и файлами\n",
        "import librosa #Параметризация аудио\n",
        "import numpy as np #Numpy массивы\n",
        "import matplotlib.pyplot as plt #Отображение графиков\n",
        "#Отрисовка графиков в ячейках collab\n",
        "%matplotlib inline \n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop #Оптимизатор для задания шага обучения\n",
        "from tensorflow.keras.models import Sequential, Model #Два формата модели keras\n",
        "from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, BatchNormalization, Flatten, Conv1D, Conv2D, LSTM, MaxPooling2D, MaxPooling1D, GlobalMaxPooling2D #Базовые слови\n",
        "from sklearn.model_selection import train_test_split #Разбиение на обучающую и проверочную выборку\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler #Для нормировки данных\n",
        "\n",
        "#Отключаем предупреждения\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDvFcj3CjnxG",
        "colab_type": "code",
        "outputId": "12a24394-2b0d-4e40-848a-d58135f09111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Подключаем Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Базу для ноутбука можно скачать по ссылке\n",
        "#http://marsyas.info/downloads/datasets.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_YQFujuobE5",
        "colab_type": "code",
        "outputId": "275ff88f-bd1a-4f55-ec1b-54c66ba2b9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import zipfile #Для разорхивации базы\n",
        "\n",
        "#Разорхивируем архив с базой\n",
        "z = zipfile.ZipFile('/content/drive/My Drive/Базы/genres.zip', 'r')\n",
        "z.extractall()\n",
        "\n",
        "#Задаём названия жанров\n",
        "#В архиве названия папок совпадают с названиями жанров\n",
        "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
        "\n",
        "#Проверяем выгруженные папки\n",
        "!ls genres \n",
        "#И одну из папок\n",
        "!ls genres/blues"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blues  classical  country  disco  hiphop  jazz\tmetal  pop  reggae  rock\n",
            "blues.00000.au\tblues.00020.au\tblues.00040.au\tblues.00060.au\tblues.00080.au\n",
            "blues.00001.au\tblues.00021.au\tblues.00041.au\tblues.00061.au\tblues.00081.au\n",
            "blues.00002.au\tblues.00022.au\tblues.00042.au\tblues.00062.au\tblues.00082.au\n",
            "blues.00003.au\tblues.00023.au\tblues.00043.au\tblues.00063.au\tblues.00083.au\n",
            "blues.00004.au\tblues.00024.au\tblues.00044.au\tblues.00064.au\tblues.00084.au\n",
            "blues.00005.au\tblues.00025.au\tblues.00045.au\tblues.00065.au\tblues.00085.au\n",
            "blues.00006.au\tblues.00026.au\tblues.00046.au\tblues.00066.au\tblues.00086.au\n",
            "blues.00007.au\tblues.00027.au\tblues.00047.au\tblues.00067.au\tblues.00087.au\n",
            "blues.00008.au\tblues.00028.au\tblues.00048.au\tblues.00068.au\tblues.00088.au\n",
            "blues.00009.au\tblues.00029.au\tblues.00049.au\tblues.00069.au\tblues.00089.au\n",
            "blues.00010.au\tblues.00030.au\tblues.00050.au\tblues.00070.au\tblues.00090.au\n",
            "blues.00011.au\tblues.00031.au\tblues.00051.au\tblues.00071.au\tblues.00091.au\n",
            "blues.00012.au\tblues.00032.au\tblues.00052.au\tblues.00072.au\tblues.00092.au\n",
            "blues.00013.au\tblues.00033.au\tblues.00053.au\tblues.00073.au\tblues.00093.au\n",
            "blues.00014.au\tblues.00034.au\tblues.00054.au\tblues.00074.au\tblues.00094.au\n",
            "blues.00015.au\tblues.00035.au\tblues.00055.au\tblues.00075.au\tblues.00095.au\n",
            "blues.00016.au\tblues.00036.au\tblues.00056.au\tblues.00076.au\tblues.00096.au\n",
            "blues.00017.au\tblues.00037.au\tblues.00057.au\tblues.00077.au\tblues.00097.au\n",
            "blues.00018.au\tblues.00038.au\tblues.00058.au\tblues.00078.au\tblues.00098.au\n",
            "blues.00019.au\tblues.00039.au\tblues.00059.au\tblues.00079.au\tblues.00099.au\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfQ-PnDJMyVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Функция параметризации аудир\n",
        "def get_features(y, sr):\n",
        "  #Получаем различные параметры аудио\n",
        "  chroma_stft = np.mean(librosa.feature.chroma_stft(y = y, sr = sr)) #Частота цветности\n",
        "  rmse = np.mean(librosa.feature.rmse(y=y)) #Среднеквадратичная амплитуда\n",
        "  spec_cent = np.mean(librosa.feature.spectral_centroid(y = y, sr = sr)) #Спектральный центроид\n",
        "  spec_bw = np.mean(librosa.feature.spectral_bandwidth(y = y, sr = sr)) #Ширина полосы частот\n",
        "  rolloff = np.mean(librosa.feature.spectral_rolloff(y = y, sr = sr)) #Спектральный спад частоты\n",
        "  zcr = np.mean(librosa.feature.zero_crossing_rate(y)) #Пересечения нуля\n",
        "  mfcc = librosa.feature.mfcc(y = y, sr = sr) #Мел кепстральные коэффициенты\n",
        "  \n",
        "  #Добавляем все параметры в один список\n",
        "  out = []\n",
        "  out.append(chroma_stft)\n",
        "  out.append(rmse)\n",
        "  out.append(spec_cent)\n",
        "  out.append(spec_bw)\n",
        "  out.append(rolloff)\n",
        "  out.append(zcr)\n",
        "  \n",
        "  #По одному добавляем все Мел коэффициенты\n",
        "  for e in mfcc:\n",
        "    out.append(np.mean(e))\n",
        "  \n",
        "  #Возвращаем получившийся список\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Up5SxKC7Pc",
        "colab_type": "code",
        "outputId": "e7b5da3f-02b9-4796-8fee-a9b55c7c2ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import time #Для подсчёта времени на обработку одного жанра\n",
        "\n",
        "#Формируем обучающую выборку\n",
        "#Создаём пустые листы\n",
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "#Запоминаем время старта формирования выборки\n",
        "curr_time = time.time()\n",
        "\n",
        "seconds = 20\n",
        "\n",
        "#Проходим по всем жарнам\n",
        "for i in range(len(genres)):\n",
        "  g = genres[i] #Берём текущий жанр\n",
        "  #Проходим по файлам папки, соответствующей текущему жанру\n",
        "  for filename in os.listdir(f'./genres/{g}'):\n",
        "    #Получаем имя песни\n",
        "    songname = f'./genres/{g}/{filename}'\n",
        "    #Загружаем в y аудиосигнал\n",
        "    #Используем первые %seconds% секунд аудио\n",
        "    y, sr = librosa.load(songname, mono=True, duration=seconds)\n",
        "    #Превращаем сигнал в параметризованные данные\n",
        "    out = get_features(y, sr)\n",
        "    \n",
        "    #Добавляем строку в X_train\n",
        "    X_train.append(out)\n",
        "    #Добавляем в Y_train номер жанра в формате ohe\n",
        "    Y_train.append(utils.to_categorical(i, len(genres)))\n",
        "\n",
        "  #Выводим информацию о готовности обработки базы\n",
        "  print(\"Жанр \", g, \" готов -> \", round(time.time() - curr_time), \"c\", sep=\"\")\n",
        "  curr_time = time.time()\n",
        "\n",
        "#Превращаем обучающую выборку на numpy массивы\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Жанр blues готов -> 68c\n",
            "Жанр classical готов -> 69c\n",
            "Жанр country готов -> 68c\n",
            "Жанр disco готов -> 68c\n",
            "Жанр hiphop готов -> 68c\n",
            "Жанр jazz готов -> 68c\n",
            "Жанр metal готов -> 68c\n",
            "Жанр pop готов -> 68c\n",
            "Жанр reggae готов -> 68c\n",
            "Жанр rock готов -> 68c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ1-UoWUNcTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём scaler для нормировки в нормальное распределение\n",
        "scaler = StandardScaler()\n",
        "#Номируем X_train\n",
        "X_train = scaler.fit_transform(np.array(X_train, dtype = float))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9U-LEeqcZCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Выводим номера классов, чтобы проверить, что всё правильно заполнилось\n",
        "#И номера классов идут последовательно крупными блоками\n",
        "y_train_class = np.argmax(Y_train, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSdgnnI_Sxir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Разделяем выборку на обучающую и проверочную\n",
        "#Для проверочной используем 10% примеров\n",
        "#Так как база маленькая\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train_class, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up_RzaPSNfVe",
        "colab_type": "code",
        "outputId": "e78cf0dc-d406-46bb-97a9-126c7cb1cda8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Выводим размеры обучающей и проверочной выборки для проверки\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(900, 26)\n",
            "(900,)\n",
            "(100, 26)\n",
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8FpsSAYyjtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Функция параметризации аудир\n",
        "def get_features_2d(y, sr):\n",
        "  #Получаем различные параметры аудио\n",
        "  chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr) #Частота цветности\n",
        "  rmse = librosa.feature.rmse(y=y) #Среднеквадратичная амплитуда\n",
        "  spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr) #Спектральный центроид\n",
        "  #spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)) #Ширина полосы частот\n",
        "  #rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)) #Спектральный спад частоты\n",
        "  #zcr = np.mean(librosa.feature.zero_crossing_rate(y)) #Пересечения нуля\n",
        "  mfcc = librosa.feature.mfcc(y=y, sr=sr) #Мел спектральные коэффициенты\n",
        "  \n",
        "  #Возвращаем получившийся список\n",
        "  return mfcc, chroma_stft, rmse, spec_cent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewvdMXGE7fWm",
        "colab_type": "code",
        "outputId": "902772ea-2fb0-4815-e3d5-5485a3c5c8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import time #Для подсчёта времени на обработку одного жанра\n",
        "\n",
        "#Формируем обучающую выборку\n",
        "#Создаём пустые листы\n",
        "X_train_mfcc = []\n",
        "X_train_chroma_stft = []\n",
        "X_train_rmse = []\n",
        "X_train_spec_cent = []\n",
        "Y_train = []\n",
        "#Запоминаем время старта формирования выборки\n",
        "curr_time = time.time()\n",
        "\n",
        "seconds = 20\n",
        "\n",
        "#Проходим по всем жарнам\n",
        "for i in range(len(genres)):\n",
        "  g = genres[i] #Берём текущий жанр\n",
        "  #Проходим по файлам папки, соответствующей текущему жанру\n",
        "  for filename in os.listdir(f'./genres/{g}'):\n",
        "    #Получаем имя песни\n",
        "    songname = f'./genres/{g}/{filename}'\n",
        "    #Загружаем в y аудиосигнал\n",
        "    #Используем первые %seconds% секунд аудио\n",
        "    y, sr = librosa.load(songname, mono=True, duration=seconds)\n",
        "    #Превращаем сигнал в параметризованные данныеБМ и питон ещё нет\n",
        "\n",
        "    for sec in range(seconds):\n",
        "      mfcc, chroma_stft, rmse, spec_cent = get_features_2d(y[sec*sr:(sec+1)*sr], sr)\n",
        "      X_train_mfcc.append(mfcc)\n",
        "      X_train_chroma_stft.append(chroma_stft)\n",
        "      X_train_rmse.append(rmse)\n",
        "      X_train_spec_cent.append(spec_cent)\n",
        "      Y_train.append(utils.to_categorical(i, len(genres)))\n",
        "\n",
        "  #Выводим информацию о готовности обработки базы\n",
        "  print(\"Жанр \", g, \" готов -> \", round(time.time() - curr_time), \"c\", sep=\"\")\n",
        "  curr_time = time.time()\n",
        "\n",
        "#Превращаем обучающую выборку на numpy массивы\n",
        "X_train_mfcc = np.array(X_train_mfcc)\n",
        "X_train_chroma_stft = np.array(X_train_chroma_stft)\n",
        "X_train_rmse = np.array(X_train_rmse)\n",
        "X_train_spec_cent = np.array(X_train_spec_cent)\n",
        "Y_train = np.array(Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Жанр blues готов -> 68c\n",
            "Жанр classical готов -> 67c\n",
            "Жанр country готов -> 68c\n",
            "Жанр disco готов -> 68c\n",
            "Жанр hiphop готов -> 69c\n",
            "Жанр jazz готов -> 70c\n",
            "Жанр metal готов -> 71c\n",
            "Жанр pop готов -> 72c\n",
            "Жанр reggae готов -> 73c\n",
            "Жанр rock готов -> 73c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XRrK5Fb8Xb7",
        "colab_type": "code",
        "outputId": "85e40cd0-3d7f-4abf-923a-8156abee7117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(X_train_mfcc.shape)\n",
        "print(X_train_chroma_stft.shape)\n",
        "print(X_train_rmse.shape)\n",
        "print(X_train_spec_cent.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 20, 44)\n",
            "(20000, 12, 44)\n",
            "(20000, 1, 44)\n",
            "(20000, 1, 44)\n",
            "(20000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjQQQPQ2KIM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_mfcc = X_train_mfcc.reshape(X_train_mfcc.shape[0], X_train_mfcc.shape[1], X_train_mfcc.shape[2], 1)\n",
        "X_train_chroma_stft = X_train_chroma_stft.reshape(X_train_chroma_stft.shape[0], X_train_chroma_stft.shape[1], X_train_chroma_stft.shape[2], 1)\n",
        "X_train_rmse = X_train_rmse.reshape(X_train_rmse.shape[0], X_train_rmse.shape[2], X_train_rmse.shape[1])\n",
        "X_train_spec_cent = X_train_spec_cent.reshape(X_train_spec_cent.shape[0], X_train_spec_cent.shape[2], X_train_spec_cent.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAtlH7KxKfWO",
        "colab_type": "code",
        "outputId": "8d8a4868-419f-4407-ef74-e530e0a2fab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(X_train_mfcc.shape)\n",
        "print(X_train_chroma_stft.shape)\n",
        "print(X_train_rmse.shape)\n",
        "print(X_train_spec_cent.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 20, 44, 1)\n",
            "(20000, 12, 44, 1)\n",
            "(20000, 44, 1)\n",
            "(20000, 44, 1)\n",
            "(20000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHCTyx4pWdIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём backup обучающей выборки\n",
        "X_train_mfcc_backup = X_train_mfcc.copy()\n",
        "X_train_chroma_stft_backup = X_train_chroma_stft.copy()\n",
        "X_train_rmse_backup = X_train_rmse.copy()\n",
        "X_train_spec_cent_backup = X_train_spec_cent.copy()\n",
        "Y_train_backup = Y_train.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTmiTMzBQm0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_mask = np.random.sample(20000)\n",
        "train_mask = val_mask < 0.8\n",
        "val_mask = val_mask >= 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyHXAY4WQvMv",
        "colab_type": "code",
        "outputId": "0cfd47ea-5827-45fa-86da-2c9985f3b286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_mask.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NWNsFTwRGOo",
        "colab_type": "code",
        "outputId": "6e5fde94-fbc1-4c50-b0e0-f5d0b8d72724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(train_mask[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True False  True  True False  True  True  True\n",
            "  True  True False False  True  True  True  True False  True  True  True\n",
            "  True  True  True  True  True  True False False  True False False  True\n",
            " False False False  True  True False  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True False  True False  True False  True\n",
            " False  True  True  True  True False  True  True  True False  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True False\n",
            " False  True  True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeBRAjGqekKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale(X):\n",
        "  min_X = X.min()\n",
        "  max_X = X.max()\n",
        "  X = (X - min_X) / (max_X - min_X)\n",
        "\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Ok1eBee2nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_mfcc_scaled = scale(X_train_mfcc)\n",
        "X_train_chroma_stft_scaled = scale(X_train_chroma_stft)\n",
        "X_train_rmse_scaled = scale(X_train_rmse)\n",
        "X_train_spec_cent_scaled = scale(X_train_spec_cent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOLPl7rCayBa",
        "colab_type": "text"
      },
      "source": [
        "##Создаём нейронку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTCBnSGEQlXb",
        "colab_type": "code",
        "outputId": "db9e4922-2d4f-4302-91f1-8272dbeab55f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        }
      },
      "source": [
        "input_mfcc = Input((20, 44, 1))\n",
        "input_chroma_stft = Input((12, 44, 1))\n",
        "input_rmse = Input((44, 1))\n",
        "input_spec_cent = Input((44, 1))\n",
        "\n",
        "x1 = BatchNormalization()(input_mfcc)\n",
        "x1 = Conv2D(256, (3,3), padding=\"same\", activation=\"elu\")(x1)\n",
        "x1 = Conv2D(256, (3,3), padding=\"same\", activation=\"elu\")(x1)\n",
        "x1 = MaxPooling2D(2)(x1)\n",
        "x1 = Conv2D(128, (3,3), padding=\"same\", activation=\"elu\")(x1)\n",
        "x1 = Conv2D(128, (3,3), padding=\"same\", activation=\"elu\")(x1)\n",
        "x1 = MaxPooling2D(2)(x1)\n",
        "x1 = Conv2D(64, (3,3), padding=\"same\", activation=\"elu\")(x1)\n",
        "x1 = Conv2D(64, (3,3), padding=\"same\", activation=\"elu\")(x1)\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "x2 = BatchNormalization()(input_chroma_stft)\n",
        "x2 = Conv2D(256, (3,3), padding=\"same\", activation=\"elu\")(x2)\n",
        "x2 = Conv2D(256, (3,3), padding=\"same\", activation=\"elu\")(x2)\n",
        "x2_gmp_1 = GlobalMaxPooling2D()(x2)\n",
        "x2 = MaxPooling2D(2)(x2)\n",
        "x2 = Conv2D(128, (3,3), padding=\"same\", activation=\"elu\")(x2)\n",
        "x2 = Conv2D(128, (3,3), padding=\"same\", activation=\"elu\")(x2)\n",
        "x2_gmp_2 = GlobalMaxPooling2D()(x2)\n",
        "x2 = MaxPooling2D(2)(x2)\n",
        "x2 = Conv2D(64, (3,3), padding=\"same\", activation=\"elu\")(x2)\n",
        "x2 = Conv2D(64, (3,3), padding=\"same\", activation=\"elu\")(x2)\n",
        "x2_gmp_3 = GlobalMaxPooling2D()(x2)\n",
        "x2 = Flatten()(x2)\n",
        "\n",
        "x3 = BatchNormalization()(input_rmse)\n",
        "x3 = Conv1D(256, 3, padding=\"same\", activation=\"elu\")(x3)\n",
        "x3 = Conv1D(256, 3, padding=\"same\", activation=\"elu\")(x3)\n",
        "x3 = MaxPooling1D(2)(x3)\n",
        "x3 = Conv1D(128, 3, padding=\"same\", activation=\"elu\")(x3)\n",
        "x3 = Conv1D(128, 3, padding=\"same\", activation=\"elu\")(x3)\n",
        "x3 = MaxPooling1D(2)(x3)\n",
        "x3 = Conv1D(64, 3, padding=\"same\", activation=\"elu\")(x3)\n",
        "x3 = Conv1D(64, 3, padding=\"same\", activation=\"elu\")(x3)\n",
        "x3 = Flatten()(x3)\n",
        "\n",
        "x4 = BatchNormalization()(input_spec_cent)\n",
        "x4 = Conv1D(256, 3, padding=\"same\", activation=\"elu\")(x4)\n",
        "x4 = Conv1D(256, 3, padding=\"same\", activation=\"elu\")(x4)\n",
        "x4 = MaxPooling1D(2)(x4)\n",
        "x4 = Conv1D(128, 3, padding=\"same\", activation=\"elu\")(x4)\n",
        "x4 = Conv1D(128, 3, padding=\"same\", activation=\"elu\")(x4)\n",
        "x4 = MaxPooling1D(2)(x4)\n",
        "x4 = Conv1D(64, 3, padding=\"same\", activation=\"elu\")(x4)\n",
        "x4 = Conv1D(64, 3, padding=\"same\", activation=\"elu\")(x4)\n",
        "x4 = Flatten()(x4)\n",
        "\n",
        "x = concatenate([x1, x2, x3, x4, x2_gmp_1, x2_gmp_2, x2_gmp_3])\n",
        "\n",
        "x = Dense(128, activation='elu')(x)\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model([input_mfcc, input_chroma_stft, input_rmse, input_spec_cent], x)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit([X_train_mfcc_scaled[train_mask], X_train_chroma_stft_scaled[train_mask], X_train_rmse_scaled[train_mask], X_train_spec_cent_scaled[train_mask]],\n",
        "                    Y_train[train_mask],\n",
        "                    epochs=20,\n",
        "                    batch_size=256,\n",
        "                    validation_data=([X_train_mfcc_scaled[val_mask], X_train_chroma_stft_scaled[val_mask], X_train_rmse_scaled[val_mask], X_train_spec_cent_scaled[val_mask]],\n",
        "                    Y_train[val_mask]))\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 10s 153ms/step - loss: 1.6709 - accuracy: 0.4390 - val_loss: 8.2053 - val_accuracy: 0.1015\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.2899 - accuracy: 0.5543 - val_loss: 27.7355 - val_accuracy: 0.1008\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.3667 - accuracy: 0.5521 - val_loss: 3.3614 - val_accuracy: 0.1124\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.2309 - accuracy: 0.5656 - val_loss: 3.4808 - val_accuracy: 0.2045\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.0082 - accuracy: 0.6605 - val_loss: 3.1127 - val_accuracy: 0.3022\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.4284 - accuracy: 0.5309 - val_loss: 2.0027 - val_accuracy: 0.2942\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.1511 - accuracy: 0.5952 - val_loss: 3.7588 - val_accuracy: 0.3082\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 0.9241 - accuracy: 0.6844 - val_loss: 2.6385 - val_accuracy: 0.4214\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 9s 140ms/step - loss: 1.0702 - accuracy: 0.6539 - val_loss: 1.9610 - val_accuracy: 0.4650\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 1.2167 - accuracy: 0.5801 - val_loss: 1.8638 - val_accuracy: 0.5101\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 0.9107 - accuracy: 0.6910 - val_loss: 0.9463 - val_accuracy: 0.6935\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 0.7587 - accuracy: 0.7382 - val_loss: 1.4654 - val_accuracy: 0.5920\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 0.8968 - accuracy: 0.6972 - val_loss: 0.8062 - val_accuracy: 0.7298\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 0.5719 - accuracy: 0.8147 - val_loss: 4.6704 - val_accuracy: 0.3683\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.3712 - accuracy: 0.5761 - val_loss: 2.1041 - val_accuracy: 0.4534\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 1.2196 - accuracy: 0.5831 - val_loss: 1.0761 - val_accuracy: 0.6373\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 0.7898 - accuracy: 0.7286 - val_loss: 1.4009 - val_accuracy: 0.5968\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 0.8471 - accuracy: 0.7055 - val_loss: 0.9139 - val_accuracy: 0.7109\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 9s 138ms/step - loss: 0.5790 - accuracy: 0.7958 - val_loss: 0.7969 - val_accuracy: 0.7422\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 9s 139ms/step - loss: 0.5756 - accuracy: 0.8147 - val_loss: 2.4729 - val_accuracy: 0.5592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c1619bef-35f5-497a-c1e5-3f8032c2600c",
        "id": "bQL_1vvxGKzI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Указываем, какие индексы данных во входных векторах брать для обучения\n",
        "#Делаем это для того, чтобы можно было экспериментировать\n",
        "#И обучать не на всех колонках данных, а на части\n",
        "indexes = range(0,26)\n",
        "\n",
        "#Создаём Dense сеть\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='elu', input_shape=(len(indexes),)))\n",
        "model.add(Dense(128, activation='elu'))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(Dense(32, activation='elu'))\n",
        "#В конце 10 нейронов и softmax, так как 10 классов\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#Компилируем сеть\n",
        "model.compile(optimizer=RMSprop(lr=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Обучаем\n",
        "history = model.fit(X_train[:, indexes],\n",
        "                    y_train,\n",
        "                    epochs=200,\n",
        "                    batch_size=20,\n",
        "                    validation_data=(X_test[:, indexes], y_test))\n",
        "\n",
        "#Выводим график точности распознавания на обучающей и проверочной выборках\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.0465 - accuracy: 0.2356 - val_loss: 1.8752 - val_accuracy: 0.3200\n",
            "Epoch 2/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.7662 - accuracy: 0.3678 - val_loss: 1.7303 - val_accuracy: 0.3200\n",
            "Epoch 3/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.6293 - accuracy: 0.4000 - val_loss: 1.6383 - val_accuracy: 0.3500\n",
            "Epoch 4/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.5360 - accuracy: 0.4200 - val_loss: 1.5689 - val_accuracy: 0.3900\n",
            "Epoch 5/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.4667 - accuracy: 0.4756 - val_loss: 1.5217 - val_accuracy: 0.4300\n",
            "Epoch 6/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.4090 - accuracy: 0.5056 - val_loss: 1.4921 - val_accuracy: 0.4400\n",
            "Epoch 7/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.3603 - accuracy: 0.5289 - val_loss: 1.4526 - val_accuracy: 0.5200\n",
            "Epoch 8/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.3198 - accuracy: 0.5411 - val_loss: 1.4215 - val_accuracy: 0.5000\n",
            "Epoch 9/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.2828 - accuracy: 0.5722 - val_loss: 1.3999 - val_accuracy: 0.5000\n",
            "Epoch 10/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.2487 - accuracy: 0.5911 - val_loss: 1.3772 - val_accuracy: 0.5100\n",
            "Epoch 11/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.2168 - accuracy: 0.6000 - val_loss: 1.3625 - val_accuracy: 0.5300\n",
            "Epoch 12/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1897 - accuracy: 0.6156 - val_loss: 1.3411 - val_accuracy: 0.5500\n",
            "Epoch 13/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1635 - accuracy: 0.6222 - val_loss: 1.3266 - val_accuracy: 0.5500\n",
            "Epoch 14/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1389 - accuracy: 0.6311 - val_loss: 1.3193 - val_accuracy: 0.5600\n",
            "Epoch 15/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1193 - accuracy: 0.6322 - val_loss: 1.3033 - val_accuracy: 0.5500\n",
            "Epoch 16/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0980 - accuracy: 0.6456 - val_loss: 1.2800 - val_accuracy: 0.5800\n",
            "Epoch 17/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0795 - accuracy: 0.6489 - val_loss: 1.2615 - val_accuracy: 0.5900\n",
            "Epoch 18/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0628 - accuracy: 0.6578 - val_loss: 1.2568 - val_accuracy: 0.5900\n",
            "Epoch 19/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0447 - accuracy: 0.6578 - val_loss: 1.2511 - val_accuracy: 0.5800\n",
            "Epoch 20/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0290 - accuracy: 0.6644 - val_loss: 1.2396 - val_accuracy: 0.6100\n",
            "Epoch 21/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0139 - accuracy: 0.6633 - val_loss: 1.2250 - val_accuracy: 0.5900\n",
            "Epoch 22/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9997 - accuracy: 0.6689 - val_loss: 1.2168 - val_accuracy: 0.6000\n",
            "Epoch 23/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9843 - accuracy: 0.6789 - val_loss: 1.2114 - val_accuracy: 0.5800\n",
            "Epoch 24/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9709 - accuracy: 0.6800 - val_loss: 1.2006 - val_accuracy: 0.6000\n",
            "Epoch 25/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9567 - accuracy: 0.6856 - val_loss: 1.1916 - val_accuracy: 0.5900\n",
            "Epoch 26/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9484 - accuracy: 0.6856 - val_loss: 1.1783 - val_accuracy: 0.6000\n",
            "Epoch 27/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9337 - accuracy: 0.6911 - val_loss: 1.1699 - val_accuracy: 0.6000\n",
            "Epoch 28/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9232 - accuracy: 0.6978 - val_loss: 1.1766 - val_accuracy: 0.5900\n",
            "Epoch 29/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9090 - accuracy: 0.7033 - val_loss: 1.1653 - val_accuracy: 0.5600\n",
            "Epoch 30/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.9014 - accuracy: 0.7011 - val_loss: 1.1531 - val_accuracy: 0.5900\n",
            "Epoch 31/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.7122 - val_loss: 1.1401 - val_accuracy: 0.6000\n",
            "Epoch 32/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8818 - accuracy: 0.7033 - val_loss: 1.1369 - val_accuracy: 0.5900\n",
            "Epoch 33/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8696 - accuracy: 0.7122 - val_loss: 1.1377 - val_accuracy: 0.5800\n",
            "Epoch 34/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8621 - accuracy: 0.7144 - val_loss: 1.1272 - val_accuracy: 0.5900\n",
            "Epoch 35/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8512 - accuracy: 0.7189 - val_loss: 1.1210 - val_accuracy: 0.6000\n",
            "Epoch 36/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8432 - accuracy: 0.7156 - val_loss: 1.1168 - val_accuracy: 0.5900\n",
            "Epoch 37/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8329 - accuracy: 0.7244 - val_loss: 1.1035 - val_accuracy: 0.6000\n",
            "Epoch 38/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8263 - accuracy: 0.7133 - val_loss: 1.1022 - val_accuracy: 0.6100\n",
            "Epoch 39/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8171 - accuracy: 0.7267 - val_loss: 1.0963 - val_accuracy: 0.6000\n",
            "Epoch 40/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8095 - accuracy: 0.7244 - val_loss: 1.1021 - val_accuracy: 0.6000\n",
            "Epoch 41/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8015 - accuracy: 0.7267 - val_loss: 1.1041 - val_accuracy: 0.6000\n",
            "Epoch 42/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7947 - accuracy: 0.7311 - val_loss: 1.0960 - val_accuracy: 0.6200\n",
            "Epoch 43/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7881 - accuracy: 0.7367 - val_loss: 1.0850 - val_accuracy: 0.6100\n",
            "Epoch 44/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7809 - accuracy: 0.7400 - val_loss: 1.0824 - val_accuracy: 0.6000\n",
            "Epoch 45/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7726 - accuracy: 0.7333 - val_loss: 1.0879 - val_accuracy: 0.6100\n",
            "Epoch 46/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7657 - accuracy: 0.7356 - val_loss: 1.0737 - val_accuracy: 0.6100\n",
            "Epoch 47/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7601 - accuracy: 0.7422 - val_loss: 1.0719 - val_accuracy: 0.6200\n",
            "Epoch 48/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.7367 - val_loss: 1.0864 - val_accuracy: 0.6000\n",
            "Epoch 49/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.7400 - val_loss: 1.0745 - val_accuracy: 0.6100\n",
            "Epoch 50/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.7500 - val_loss: 1.0739 - val_accuracy: 0.6100\n",
            "Epoch 51/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.7500 - val_loss: 1.0698 - val_accuracy: 0.6200\n",
            "Epoch 52/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7263 - accuracy: 0.7500 - val_loss: 1.0611 - val_accuracy: 0.6300\n",
            "Epoch 53/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.7556 - val_loss: 1.0612 - val_accuracy: 0.6000\n",
            "Epoch 54/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7162 - accuracy: 0.7544 - val_loss: 1.0546 - val_accuracy: 0.6100\n",
            "Epoch 55/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.7533 - val_loss: 1.0679 - val_accuracy: 0.6100\n",
            "Epoch 56/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.7500 - val_loss: 1.0484 - val_accuracy: 0.6100\n",
            "Epoch 57/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.7656 - val_loss: 1.0497 - val_accuracy: 0.6300\n",
            "Epoch 58/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.7578 - val_loss: 1.0533 - val_accuracy: 0.6200\n",
            "Epoch 59/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.7678 - val_loss: 1.0436 - val_accuracy: 0.6200\n",
            "Epoch 60/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.7633 - val_loss: 1.0452 - val_accuracy: 0.6100\n",
            "Epoch 61/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.7700 - val_loss: 1.0439 - val_accuracy: 0.6200\n",
            "Epoch 62/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.7700 - val_loss: 1.0578 - val_accuracy: 0.6100\n",
            "Epoch 63/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.7711 - val_loss: 1.0394 - val_accuracy: 0.6200\n",
            "Epoch 64/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7700 - val_loss: 1.0467 - val_accuracy: 0.6200\n",
            "Epoch 65/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.7767 - val_loss: 1.0371 - val_accuracy: 0.6300\n",
            "Epoch 66/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.7689 - val_loss: 1.0500 - val_accuracy: 0.6300\n",
            "Epoch 67/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7789 - val_loss: 1.0371 - val_accuracy: 0.6200\n",
            "Epoch 68/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7722 - val_loss: 1.0370 - val_accuracy: 0.6200\n",
            "Epoch 69/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7789 - val_loss: 1.0279 - val_accuracy: 0.6100\n",
            "Epoch 70/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.7833 - val_loss: 1.0411 - val_accuracy: 0.6300\n",
            "Epoch 71/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.7811 - val_loss: 1.0305 - val_accuracy: 0.6300\n",
            "Epoch 72/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7800 - val_loss: 1.0372 - val_accuracy: 0.6100\n",
            "Epoch 73/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.7867 - val_loss: 1.0341 - val_accuracy: 0.6300\n",
            "Epoch 74/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.7944 - val_loss: 1.0181 - val_accuracy: 0.6400\n",
            "Epoch 75/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7889 - val_loss: 1.0345 - val_accuracy: 0.6300\n",
            "Epoch 76/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7933 - val_loss: 1.0333 - val_accuracy: 0.6300\n",
            "Epoch 77/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.8011 - val_loss: 1.0252 - val_accuracy: 0.6400\n",
            "Epoch 78/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.8022 - val_loss: 1.0282 - val_accuracy: 0.6400\n",
            "Epoch 79/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.8011 - val_loss: 1.0404 - val_accuracy: 0.6200\n",
            "Epoch 80/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.8022 - val_loss: 1.0312 - val_accuracy: 0.6300\n",
            "Epoch 81/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7989 - val_loss: 1.0280 - val_accuracy: 0.6200\n",
            "Epoch 82/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8100 - val_loss: 1.0275 - val_accuracy: 0.6300\n",
            "Epoch 83/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.8044 - val_loss: 1.0157 - val_accuracy: 0.6300\n",
            "Epoch 84/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.8022 - val_loss: 1.0204 - val_accuracy: 0.6400\n",
            "Epoch 85/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.8111 - val_loss: 1.0319 - val_accuracy: 0.6200\n",
            "Epoch 86/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.8122 - val_loss: 1.0284 - val_accuracy: 0.6300\n",
            "Epoch 87/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.8144 - val_loss: 1.0155 - val_accuracy: 0.6300\n",
            "Epoch 88/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.8133 - val_loss: 1.0377 - val_accuracy: 0.6300\n",
            "Epoch 89/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.8211 - val_loss: 1.0187 - val_accuracy: 0.6200\n",
            "Epoch 90/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.8122 - val_loss: 1.0238 - val_accuracy: 0.6400\n",
            "Epoch 91/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.8144 - val_loss: 1.0299 - val_accuracy: 0.6300\n",
            "Epoch 92/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.8211 - val_loss: 1.0221 - val_accuracy: 0.6300\n",
            "Epoch 93/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.8200 - val_loss: 1.0290 - val_accuracy: 0.6400\n",
            "Epoch 94/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.8200 - val_loss: 1.0160 - val_accuracy: 0.6400\n",
            "Epoch 95/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.8333 - val_loss: 1.0278 - val_accuracy: 0.6200\n",
            "Epoch 96/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.8278 - val_loss: 1.0278 - val_accuracy: 0.6400\n",
            "Epoch 97/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8256 - val_loss: 1.0327 - val_accuracy: 0.6300\n",
            "Epoch 98/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8300 - val_loss: 1.0379 - val_accuracy: 0.6300\n",
            "Epoch 99/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.8333 - val_loss: 1.0326 - val_accuracy: 0.6500\n",
            "Epoch 100/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.8344 - val_loss: 1.0167 - val_accuracy: 0.6600\n",
            "Epoch 101/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8356 - val_loss: 1.0201 - val_accuracy: 0.6400\n",
            "Epoch 102/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.8400 - val_loss: 1.0401 - val_accuracy: 0.6300\n",
            "Epoch 103/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8478 - val_loss: 1.0460 - val_accuracy: 0.6300\n",
            "Epoch 104/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.8389 - val_loss: 1.0274 - val_accuracy: 0.6400\n",
            "Epoch 105/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8400 - val_loss: 1.0283 - val_accuracy: 0.6400\n",
            "Epoch 106/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8433 - val_loss: 1.0237 - val_accuracy: 0.6400\n",
            "Epoch 107/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8456 - val_loss: 1.0243 - val_accuracy: 0.6400\n",
            "Epoch 108/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.8478 - val_loss: 1.0289 - val_accuracy: 0.6400\n",
            "Epoch 109/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.8411 - val_loss: 1.0280 - val_accuracy: 0.6300\n",
            "Epoch 110/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.8478 - val_loss: 1.0303 - val_accuracy: 0.6200\n",
            "Epoch 111/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8522 - val_loss: 1.0568 - val_accuracy: 0.6100\n",
            "Epoch 112/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.8511 - val_loss: 1.0265 - val_accuracy: 0.6300\n",
            "Epoch 113/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8544 - val_loss: 1.0311 - val_accuracy: 0.6400\n",
            "Epoch 114/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.8578 - val_loss: 1.0242 - val_accuracy: 0.6400\n",
            "Epoch 115/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8578 - val_loss: 1.0614 - val_accuracy: 0.6200\n",
            "Epoch 116/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8667 - val_loss: 1.0286 - val_accuracy: 0.6700\n",
            "Epoch 117/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8622 - val_loss: 1.0317 - val_accuracy: 0.6600\n",
            "Epoch 118/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8689 - val_loss: 1.0364 - val_accuracy: 0.6400\n",
            "Epoch 119/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8656 - val_loss: 1.0265 - val_accuracy: 0.6500\n",
            "Epoch 120/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8667 - val_loss: 1.0274 - val_accuracy: 0.6500\n",
            "Epoch 121/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8667 - val_loss: 1.0698 - val_accuracy: 0.6200\n",
            "Epoch 122/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8700 - val_loss: 1.0408 - val_accuracy: 0.6500\n",
            "Epoch 123/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8711 - val_loss: 1.0335 - val_accuracy: 0.6600\n",
            "Epoch 124/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8744 - val_loss: 1.0242 - val_accuracy: 0.6700\n",
            "Epoch 125/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8778 - val_loss: 1.0164 - val_accuracy: 0.6700\n",
            "Epoch 126/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8789 - val_loss: 1.0513 - val_accuracy: 0.6600\n",
            "Epoch 127/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8822 - val_loss: 1.0494 - val_accuracy: 0.6700\n",
            "Epoch 128/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8800 - val_loss: 1.0481 - val_accuracy: 0.6500\n",
            "Epoch 129/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8789 - val_loss: 1.0343 - val_accuracy: 0.6800\n",
            "Epoch 130/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8811 - val_loss: 1.0471 - val_accuracy: 0.6500\n",
            "Epoch 131/200\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8822 - val_loss: 1.0618 - val_accuracy: 0.6500\n",
            "Epoch 132/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8833 - val_loss: 1.0589 - val_accuracy: 0.6500\n",
            "Epoch 133/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8856 - val_loss: 1.0445 - val_accuracy: 0.6600\n",
            "Epoch 134/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8889 - val_loss: 1.0439 - val_accuracy: 0.6600\n",
            "Epoch 135/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8822 - val_loss: 1.0565 - val_accuracy: 0.6500\n",
            "Epoch 136/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8900 - val_loss: 1.0782 - val_accuracy: 0.6300\n",
            "Epoch 137/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8911 - val_loss: 1.0821 - val_accuracy: 0.6400\n",
            "Epoch 138/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8844 - val_loss: 1.0720 - val_accuracy: 0.6600\n",
            "Epoch 139/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8933 - val_loss: 1.0484 - val_accuracy: 0.6600\n",
            "Epoch 140/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.9011 - val_loss: 1.0546 - val_accuracy: 0.6800\n",
            "Epoch 141/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8889 - val_loss: 1.0653 - val_accuracy: 0.6600\n",
            "Epoch 142/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8933 - val_loss: 1.0723 - val_accuracy: 0.6600\n",
            "Epoch 143/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8933 - val_loss: 1.0607 - val_accuracy: 0.6700\n",
            "Epoch 144/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8944 - val_loss: 1.0804 - val_accuracy: 0.6700\n",
            "Epoch 145/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.9000 - val_loss: 1.0757 - val_accuracy: 0.6700\n",
            "Epoch 146/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.9022 - val_loss: 1.0775 - val_accuracy: 0.6500\n",
            "Epoch 147/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.9022 - val_loss: 1.0895 - val_accuracy: 0.6500\n",
            "Epoch 148/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.9011 - val_loss: 1.0461 - val_accuracy: 0.6800\n",
            "Epoch 149/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.9033 - val_loss: 1.0879 - val_accuracy: 0.6400\n",
            "Epoch 150/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.9133 - val_loss: 1.0841 - val_accuracy: 0.6600\n",
            "Epoch 151/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.9022 - val_loss: 1.0961 - val_accuracy: 0.6500\n",
            "Epoch 152/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.9089 - val_loss: 1.0971 - val_accuracy: 0.6700\n",
            "Epoch 153/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.9133 - val_loss: 1.0851 - val_accuracy: 0.7000\n",
            "Epoch 154/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.9144 - val_loss: 1.0813 - val_accuracy: 0.6900\n",
            "Epoch 155/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.9167 - val_loss: 1.0825 - val_accuracy: 0.6600\n",
            "Epoch 156/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.9133 - val_loss: 1.0857 - val_accuracy: 0.6400\n",
            "Epoch 157/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2938 - accuracy: 0.9167 - val_loss: 1.1174 - val_accuracy: 0.6500\n",
            "Epoch 158/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.9200 - val_loss: 1.1088 - val_accuracy: 0.6700\n",
            "Epoch 159/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.9211 - val_loss: 1.1039 - val_accuracy: 0.6700\n",
            "Epoch 160/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.9200 - val_loss: 1.0832 - val_accuracy: 0.6800\n",
            "Epoch 161/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.9211 - val_loss: 1.0968 - val_accuracy: 0.6900\n",
            "Epoch 162/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.9233 - val_loss: 1.1020 - val_accuracy: 0.6700\n",
            "Epoch 163/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.9244 - val_loss: 1.1260 - val_accuracy: 0.6700\n",
            "Epoch 164/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.9311 - val_loss: 1.1213 - val_accuracy: 0.6600\n",
            "Epoch 165/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.9289 - val_loss: 1.1198 - val_accuracy: 0.6500\n",
            "Epoch 166/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2651 - accuracy: 0.9322 - val_loss: 1.1187 - val_accuracy: 0.6700\n",
            "Epoch 167/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.9256 - val_loss: 1.1343 - val_accuracy: 0.6400\n",
            "Epoch 168/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9400 - val_loss: 1.1226 - val_accuracy: 0.6600\n",
            "Epoch 169/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.9256 - val_loss: 1.1314 - val_accuracy: 0.6800\n",
            "Epoch 170/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9322 - val_loss: 1.1302 - val_accuracy: 0.6900\n",
            "Epoch 171/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9333 - val_loss: 1.1704 - val_accuracy: 0.6700\n",
            "Epoch 172/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9322 - val_loss: 1.1560 - val_accuracy: 0.6400\n",
            "Epoch 173/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9378 - val_loss: 1.1249 - val_accuracy: 0.6700\n",
            "Epoch 174/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9411 - val_loss: 1.1492 - val_accuracy: 0.6700\n",
            "Epoch 175/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.9456 - val_loss: 1.1460 - val_accuracy: 0.7000\n",
            "Epoch 176/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9344 - val_loss: 1.1539 - val_accuracy: 0.6800\n",
            "Epoch 177/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9456 - val_loss: 1.1438 - val_accuracy: 0.6900\n",
            "Epoch 178/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9367 - val_loss: 1.1378 - val_accuracy: 0.6900\n",
            "Epoch 179/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9444 - val_loss: 1.1484 - val_accuracy: 0.6800\n",
            "Epoch 180/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9444 - val_loss: 1.1793 - val_accuracy: 0.6700\n",
            "Epoch 181/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9467 - val_loss: 1.1848 - val_accuracy: 0.6700\n",
            "Epoch 182/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9411 - val_loss: 1.1745 - val_accuracy: 0.6900\n",
            "Epoch 183/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9433 - val_loss: 1.1761 - val_accuracy: 0.6800\n",
            "Epoch 184/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9500 - val_loss: 1.1925 - val_accuracy: 0.6700\n",
            "Epoch 185/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9489 - val_loss: 1.1759 - val_accuracy: 0.6700\n",
            "Epoch 186/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9489 - val_loss: 1.2106 - val_accuracy: 0.6600\n",
            "Epoch 187/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9456 - val_loss: 1.2195 - val_accuracy: 0.6700\n",
            "Epoch 188/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9511 - val_loss: 1.1775 - val_accuracy: 0.6700\n",
            "Epoch 189/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9544 - val_loss: 1.1999 - val_accuracy: 0.6800\n",
            "Epoch 190/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9578 - val_loss: 1.1911 - val_accuracy: 0.7000\n",
            "Epoch 191/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9489 - val_loss: 1.2047 - val_accuracy: 0.6900\n",
            "Epoch 192/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9544 - val_loss: 1.1914 - val_accuracy: 0.6800\n",
            "Epoch 193/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9578 - val_loss: 1.2074 - val_accuracy: 0.7000\n",
            "Epoch 194/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9556 - val_loss: 1.2226 - val_accuracy: 0.7000\n",
            "Epoch 195/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9533 - val_loss: 1.2351 - val_accuracy: 0.6800\n",
            "Epoch 196/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9500 - val_loss: 1.2220 - val_accuracy: 0.6700\n",
            "Epoch 197/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9600 - val_loss: 1.2188 - val_accuracy: 0.6700\n",
            "Epoch 198/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1776 - accuracy: 0.9622 - val_loss: 1.2470 - val_accuracy: 0.6900\n",
            "Epoch 199/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9589 - val_loss: 1.2229 - val_accuracy: 0.7000\n",
            "Epoch 200/200\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9578 - val_loss: 1.2503 - val_accuracy: 0.6800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nif8H73xlqD6oAAIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}