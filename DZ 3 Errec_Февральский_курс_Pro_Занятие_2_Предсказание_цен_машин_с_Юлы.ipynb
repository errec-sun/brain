{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Февральский курс. Pro. Занятие 2. Предсказание цен машин с Юлы",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/errec-sun/brain/blob/master/DZ%203%20Errec_%D0%A4%D0%B5%D0%B2%D1%80%D0%B0%D0%BB%D1%8C%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D1%83%D1%80%D1%81_Pro_%D0%97%D0%B0%D0%BD%D1%8F%D1%82%D0%B8%D0%B5_2_%D0%9F%D1%80%D0%B5%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%B0%D0%BD%D0%B8%D0%B5_%D1%86%D0%B5%D0%BD_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD_%D1%81_%D0%AE%D0%BB%D1%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvQeueuAX4Jd",
        "colab_type": "code",
        "outputId": "68887dc2-a4c8-4dc3-8250-282f3246da15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "from google.colab import files\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adadelta, Adam\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O10ZA-msmjvL",
        "colab_type": "text"
      },
      "source": [
        "#Загрузка данных\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/Hm41rb1zqQo?t=7582"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVAD74YJKPSc",
        "colab_type": "code",
        "outputId": "827969cb-3262-4ad0-c6ff-52d368cf8b2b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "#Загружаем файлы\n",
        "files.upload()\n",
        "!ls #Выводим содержимое корневой папки"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d42b15b6-2ee8-47f7-adc4-721ef45bdd96\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d42b15b6-2ee8-47f7-adc4-721ef45bdd96\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cars_new for Python.csv to cars_new for Python.csv\n",
            "'cars_new for Python.csv'   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX0gMyfrm67-",
        "colab_type": "code",
        "outputId": "80d78d20-d36a-4ab7-bcd1-b9230994e8cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "#Считываем csv с помощью pandas\n",
        "cars = pd.read_csv('cars_new for Python.csv', sep=',')\n",
        "cars[:5] #Выводим первые 5 машин "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mark</th>\n",
              "      <th>model</th>\n",
              "      <th>price</th>\n",
              "      <th>year</th>\n",
              "      <th>mileage</th>\n",
              "      <th>body</th>\n",
              "      <th>kpp</th>\n",
              "      <th>fuel</th>\n",
              "      <th>volume</th>\n",
              "      <th>power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kia</td>\n",
              "      <td>cerato</td>\n",
              "      <td>996000</td>\n",
              "      <td>2018</td>\n",
              "      <td>28000</td>\n",
              "      <td>седан</td>\n",
              "      <td>автомат</td>\n",
              "      <td>бензин</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>daewoo</td>\n",
              "      <td>nexia 1 поколение [2-й рестайлинг]</td>\n",
              "      <td>140200</td>\n",
              "      <td>2012</td>\n",
              "      <td>60500</td>\n",
              "      <td>седан</td>\n",
              "      <td>механика</td>\n",
              "      <td>бензин</td>\n",
              "      <td>1.5</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>suzuki</td>\n",
              "      <td>jimny 3 поколение [рестайлинг]</td>\n",
              "      <td>750000</td>\n",
              "      <td>2011</td>\n",
              "      <td>29000</td>\n",
              "      <td>внедорожник</td>\n",
              "      <td>автомат</td>\n",
              "      <td>бензин</td>\n",
              "      <td>1.3</td>\n",
              "      <td>85.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bmw</td>\n",
              "      <td>x1 18 e84 [рестайлинг]</td>\n",
              "      <td>970000</td>\n",
              "      <td>2014</td>\n",
              "      <td>49500</td>\n",
              "      <td>кроссовер</td>\n",
              "      <td>автомат</td>\n",
              "      <td>бензин</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chevrolet</td>\n",
              "      <td>lacetti 1 поколение</td>\n",
              "      <td>205000</td>\n",
              "      <td>2007</td>\n",
              "      <td>151445</td>\n",
              "      <td>седан</td>\n",
              "      <td>механика</td>\n",
              "      <td>бензин</td>\n",
              "      <td>1.4</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        mark                               model   price  ...    fuel  volume  power\n",
              "0        kia                              cerato  996000  ...  бензин     2.0  150.0\n",
              "1     daewoo  nexia 1 поколение [2-й рестайлинг]  140200  ...  бензин     1.5   80.0\n",
              "2     suzuki      jimny 3 поколение [рестайлинг]  750000  ...  бензин     1.3   85.0\n",
              "3        bmw              x1 18 e84 [рестайлинг]  970000  ...  бензин     2.0  150.0\n",
              "4  chevrolet                 lacetti 1 поколение  205000  ...  бензин     1.4   95.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxh46Ndz4xNZ",
        "colab_type": "code",
        "outputId": "60cae212-9cd9-4fdb-abe6-426beae46c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(cars.values.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70119, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXlgXPAem_mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём словарь поле - его индекс\n",
        "def create_dict(s):\n",
        "  ret = {} #Создаём пустой словарь\n",
        "  for _id, name in enumerate(s): #Проходим по всем парам - id и название\n",
        "    ret.update({name: _id}) #Добавляем в словарь\n",
        "  return ret\n",
        "\n",
        "#ФУнкция преобразования в one hot encoding\n",
        "def to_ohe(value, d):\n",
        "  arr = [0] * len(d)\n",
        "  arr[d[value]] = 1\n",
        "  return arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhaCKb-3nCIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём словари по всем текстовым колонкам\n",
        "marks_dict = create_dict(set(cars['mark']))\n",
        "models_dict = create_dict(set(cars['model']))\n",
        "bodies_dict = create_dict(set(cars['body']))\n",
        "kpps_dict = create_dict(set(cars['kpp']))\n",
        "fuels_dict = create_dict(set(cars['fuel']))\n",
        "\n",
        "#Запоминаем цены\n",
        "prices = np.array(cars['price'], dtype=np.float)\n",
        "\n",
        "#Запоминаем числовые параметры\n",
        "#И нормируем\n",
        "years = preprocessing.scale(cars['year'])\n",
        "mileages = preprocessing.scale(cars['mileage'])\n",
        "volumes = preprocessing.scale(cars['volume'])\n",
        "powers = preprocessing.scale(cars['power'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MdND_2CBXmH",
        "colab_type": "code",
        "outputId": "3ff60554-7bf9-4126-d8b4-fc37eed8f1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(marks_dict)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'daewoo': 0, 'opel': 1, 'kia': 2, 'nissan': 3, 'toyota': 4, 'mercedes-benz': 5, 'honda': 6, 'ford': 7, 'volkswagen': 8, 'suzuki': 9, 'chevrolet': 10, 'bmw': 11, 'peugeot': 12, 'hyundai': 13, 'chery': 14, 'renault': 15, 'subaru': 16, 'mazda': 17, 'audi': 18, 'mitsubishi': 19, 'skoda': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXEs8aZiMdBM",
        "colab_type": "text"
      },
      "source": [
        "0 Создаем полную базу данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFQNnvd7nJBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNsvGyHXl8sr",
        "colab_type": "code",
        "outputId": "12ade04b-7a28-4382-dede-3a057dfb7a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "#Выводим один x_train\n",
        "print(x_train[0,:20])\n",
        "print(x_train[0,-20:])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 1.          0.          0.          0.          0.          0.\n",
            "  0.          1.          0.          0.          0.          0.\n",
            "  0.          1.          0.          0.          1.5200145  -1.40018212\n",
            "  0.12288486  0.22905575]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZCBfyifHRhZ",
        "colab_type": "text"
      },
      "source": [
        "#Нейронка\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/Hm41rb1zqQo?t=8166"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsiHCClRSUI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "832975ca-29ee-4216-ed72-9a7f49a62422"
      },
      "source": [
        "#Создаём сеть\n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 310s 5ms/sample - loss: 0.5098 - val_loss: 0.4798\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 308s 5ms/sample - loss: 0.3127 - val_loss: 0.3895\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 309s 5ms/sample - loss: 0.2583 - val_loss: 0.3462\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 307s 5ms/sample - loss: 0.2306 - val_loss: 0.3238\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 309s 5ms/sample - loss: 0.2120 - val_loss: 0.3011\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 305s 5ms/sample - loss: 0.1980 - val_loss: 0.2874\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 307s 5ms/sample - loss: 0.1869 - val_loss: 0.2748\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 306s 5ms/sample - loss: 0.1780 - val_loss: 0.2650\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 308s 5ms/sample - loss: 0.1707 - val_loss: 0.2565\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1639 - val_loss: 0.2489\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1582 - val_loss: 0.2435\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1536 - val_loss: 0.2374\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1493 - val_loss: 0.2321\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1452 - val_loss: 0.2278\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 306s 5ms/sample - loss: 0.1417 - val_loss: 0.2228\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 306s 5ms/sample - loss: 0.1384 - val_loss: 0.2189\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1353 - val_loss: 0.2147\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 300s 5ms/sample - loss: 0.1326 - val_loss: 0.2122\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 301s 5ms/sample - loss: 0.1297 - val_loss: 0.2080\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 302s 5ms/sample - loss: 0.1276 - val_loss: 0.2054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Средняя ошибка:  75725.0\n",
            "Средняя цена:  530277.0\n",
            "Процент ошибки: 14.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWtHB2eBIUMa",
        "colab_type": "text"
      },
      "source": [
        "1.1 создаем базу данных\n",
        ", **марки и модели** машин не включаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hRN7v2iH6rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr =  to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvbw0LNrJLTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AioooPUoJm87",
        "colab_type": "code",
        "outputId": "44a36659-28db-4d33-f3a8-8affb0c720f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Создаём сеть\n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.4923 - val_loss: 0.4638\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.3062 - val_loss: 0.3909\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.2678 - val_loss: 0.3604\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.2471 - val_loss: 0.3412\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.2331 - val_loss: 0.3250\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.2232 - val_loss: 0.3149\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.2153 - val_loss: 0.3051\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.2084 - val_loss: 0.2989\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.2034 - val_loss: 0.2910\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1983 - val_loss: 0.2847\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.1948 - val_loss: 0.2819\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1914 - val_loss: 0.2769\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1884 - val_loss: 0.2731\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.1855 - val_loss: 0.2685\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1831 - val_loss: 0.2656\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1807 - val_loss: 0.2618\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.1784 - val_loss: 0.2601\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.1764 - val_loss: 0.2575\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1745 - val_loss: 0.2546\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1729 - val_loss: 0.2519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3hUZfbA8e9J7wkp9BSkCgk1IIog\ngiI2sCFYQVxZC9bVXXfdVUTZn93dVVfXgrouIlbE3iiCSlUEAtIDJEBIgYQ00t7fH/dmmIRJg0wm\nIefzPPPMndvmzE0yJ2+57yvGGJRSSqnqvDwdgFJKqeZJE4RSSimXNEEopZRySROEUkoplzRBKKWU\ncsnH0wE0lujoaJOQkODpMJRSqkVZs2ZNljEmxtW2kyZBJCQksHr1ak+HoZRSLYqI7Kppm1urmERk\nrIhsFpFtInK/i+1TRCRTRNbaj985bZssIlvtx2R3xqmUUupYbitBiIg38AJwLpAGrBKRBcaYjdV2\nnWeMmV7t2EjgISAZMMAa+9iD7opXKaVUVe4sQQwBthljdhhjSoB3gPH1PPY84BtjTI6dFL4Bxrop\nTqWUUi64sw2iE7DH6XUacJqL/S4XkRHAFuBuY8yeGo7t5K5AVctUWlpKWloaxcXFng5FqWYvICCA\nzp074+vrW+9jPN1I/Qkw1xhzRER+D7wJjKrvwSIyDZgGEBcX554IVbOVlpZGaGgoCQkJiIinw1Gq\n2TLGkJ2dTVpaGl26dKn3ce6sYkoHYp1ed7bXORhjso0xR+yXrwKD6nusffzLxphkY0xyTIzLXlrq\nJFZcXExUVJQmB6XqICJERUU1uLTtzgSxCuguIl1ExA+YBCxw3kFEOji9HAdsspe/AsaISBsRaQOM\nsdcpVYUmB6Xq53j+VtxWxWSMKROR6Vhf7N7AbGNMiojMBFYbYxYAd4jIOKAMyAGm2MfmiMgjWEkG\nYKYxJscdceYWlvLGj6mM7BlDv9gId7yFUkq1SG69D8IY87kxpocxpqsxZpa97kE7OWCM+bMxpo8x\npp8x5mxjzG9Ox842xnSzH6+7K0bxgme/3cJPO7Ld9RbqJJWWlsb48ePp3r07Xbt25c4776SkpKRR\nzl1eXs4TTzzBGWecwcCBA3nllVca5bzu8uqrrzJ8+HCSk5OZMWOGp8NpVnbv3s11113HkCFDSExM\nJCsry9Mh1ZunG6k9LizAl8hgP3ZlF3g6FNWCGGO47LLLuOWWW/j4448pLy9n2rRpPPDAAzz55JMn\nfP4ZM2bg5eXFd999R2BgYCNE7D6vvfYay5cv59NPPyU8PNzT4TQrxcXFXHXVVcyaNYuzzjqrxVWJ\n6mB9QFxkELuyCz0dhmpBFi5cSEBAADfccAMA3t7ePPvss8yePZvCwkLeeOMNpk+37v9cvXo1I0eO\nBKCsrIzo6GgAFi9ezEUXXQRATk4OERERPPXUUwDMmTOHpUuXMmTIEEaPHs3u3bsBmDJlCu+//z4A\nt9xyi+O/9U8++YTTTjuNAQMGcM4555CRkXFMzM4xAUyfPp033ngDgJkzZzJ48GASExOZNm0armaa\nTE1NZdSoUfTt27dKTC+//DJ79uzhzDPPZOjQoaxbt46Kigq6d+9OZmYmABUVFXTr1o3MzExGjhzp\nGBbHOaaaPoPzPrNmzaJHjx4kJiby8MMPO2ILCQlxLCcmJpKamnrMZywoKGDq1KkMGTKEAQMG8PHH\nHzvOLyL89ptVgbFp0yZExHGcM+fYnd83Pz+f0aNHM3DgQJKSkhznXrhwIUVFRUyfPp2kpCT+9Kc/\nOY6dO3cuSUlJJCYmVlkfEhLC3XffTZ8+fRg9erTjGm7fvp2xY8cyaNAghg8f7ojXnVp9CQIgISqI\nVal6k3ZL9vAnKWzcm9eo5+zdMYyHLu7jcltKSgqDBg2qsi4sLIy4uDi2bdvW4Pf6v//7vypdtXfu\n3MlDDz3E5MmTmT17NnfccQfz5893bJ85cyYVFRWOBHHmmWeyfPlyRIRXX32VJ554gqeffrre7z99\n+nQefPBBAK677jo+/fRTLr744ir73H777UyePPmYmA4cOMAFF1zAQw89xMKFC7n++utZu3Yt1157\nLXPmzOGuu+7i22+/pV+/fsTExODl5eUyAdX1GZYsWcJrr73GL7/8QkBAACNHjmTYsGGcc8459fqM\ns2bNYtSoUcyePZtDhw4xZMgQx7FDhgxh9uzZPPHEE8yePZvTTnN1y1bNAgIC+OijjwgLCyMrK4uh\nQ4cybtw4MjMzSU9PZ8OGDbRp04YxY8Ywf/58hgwZwp/+9CfWrFlTZf0ll1xCQUEBycnJPPvss8yc\nOZOHH36Y559/nmnTpvHSSy/RvXt3VqxYwa233srChQsbFGdDaYIA4qOC+fjXvRwpK8ffx9vT4ahW\nJj09neXLl3PppZc61nl5eXH11VcD1hf2H//4R8e2N954g2+++YY9e47eS5qWlsbEiRPZt28fJSUl\nNfZ1nzdvHsuWLXO8b3JyMgCLFi3iiSeeoLCwkJycHPr06XNMgvjpp5/48MMPj4nJGMN1110HwKhR\no8jOziYvL4+pU6cyfvx47rrrLmbPnu0obXXu3JlffvmFwYMHVzl/bZ9h3rx5zJ8/nwkTJjiqsSZN\nmsT3339f7wTx9ddfs2DBAkcprbi42FEKGjx4ML/88gvFxcWsXbvWcV1cueaaaxzVfkVFRY5r8Je/\n/IXvv/8eLy8v0tPTycjIwBjDeeedR2U3/GuuuYbvv/8eEWHkyJHHrL/kkkvw8vJi4sSJAFx77bVc\ndtll5Ofn8+OPPzJhwgRHHEeOHMHdNEEA8VFBGAN7coro1jak7gNUs1PTf/ru0rt3b0dVT6W8vDx2\n795Nt27d+Pnnn+t9rocffpi//e1v/Pjjj451oaGhNe6fk5PDs88+y7333st///tfwPrv/p577mHc\nuHEsXry4xobiiRMn8vzzzwM4qm2Ki4u59dZbWb16NbGxscyYMaNB/eXDwsJcro+NjaVdu3YsXLiQ\nlStXMmfOHAD+8pe/MHnyZF544QUOHjzIuHHj6vwMEydOZNCgQaxbt67ecVVnjOGDDz6gZ8+eVdav\nWLECgLFjx3L77bdz/vnns2PHjhrPM2fOHEcCqaximjNnDpmZmaxZswZfX18SEhIoLi6u8do0hIhQ\nUVFBREQEa9euPeHzNYS2QWCVIAB252hDtaqf0aNHU1hY6PiCLi8v5w9/+ANTpkwhKCio3ufZvn07\nqampjBkzpsr6wYMH88477wDWl8/w4cMd2+655x5uvfVW9u7dy9dffw1Abm4unTpZo9G8+eabDfos\nlckgOjqa/Pz8YxJfpTPOOMNlTKeddprjy3/x4sVER0c7vhh/97vfce211zJhwgS8va3Sea9evVix\nYgW//vorM2fOdJy/rs8wYsQIPvvsM3JzcykpKWHevHmOtp36OO+883juuecc1Vu//PJLle3XXXcd\nP/74I9dee229z+kce9u2bfH19WXRokXs2mWNoD1o0CAWLlxIVlYW5eXlzJ07l7POOoshQ4awZMmS\nY9aD1V5T+TN4++23OfPMMwkLC6NLly689957gJXsfv311wbH2VBagsAqQQCkZmlDtaofEeGjjz7i\n1ltv5ZFHHqGiooILLriAv//97459PvzwQ9auXUt+fj47d+7kzDPPPOY8v/32G6+/fmwv7ueff54b\nb7yRJ598krZt2zJ79uxj9vnPf/7DuHHjWLVqFTNmzGDChAm0adOGUaNGsXPnznp/loiICG666SYS\nExNp3779MVU/lZ577jluuOEGnnzySWJiYhxxP/LII0yZMoW+ffsSEhJS5ct93Lhx3HDDDY7qpdrU\n9Rm6du3Kfffdx7BhwxARJk6cyKhR1sg8RUVFjuu7c+dOJkyYgL+/Pzt27ODrr79m7Nix/O1vf+Ou\nu+6ib9++VFRU0KVLFz799FPH+du2bUtKSkq9r5uza665hosvvpikpCSSk5Pp1asXAPHx8cyYMYMR\nI0bg7e3NhRdeyPjx1piljz32GGeffTbGmCrrg4ODWblyJY8++iht27Zl3rx5gJWUb7nlFh599FFK\nS0uZNGkS/fr1O65460tcNRa1RMnJyeZ4JwwyxpA042suH9iJh8cnNnJkyl02bdrEqaee6ukwVC1W\nr17N3XffzdKlSz0Ww5QpU5gxYwYtZcbJkJAQ8vPz3XJuV38zIrLGGOOy0UVLEFj/DcZHBbErR0sQ\nSjWWxx57jBdffNFR/eQpl19+OW3atPFoDC2VtkHY4qP0XgilGtP999/Prl27XFatNaWLL764Rd3A\n567Sw/HQBGGLjwom7WAhZeUVng5FKaWaBU0QtvjIIErLDftydfIZpZQCTRAOlV1dU3VMJqWUAjRB\nOCREW11dtR1CKaUsmiBs7UID8PPx0lFdVb3pcN/qRBUVFfHnP/+ZoUOH0r9/fz7//HNPh1SFJggA\nY/DCEK+juqp6qhzu+5JLLmHr1q1s2bKF/Px8HnjggUY5/4wZMygoKOC7777j559/5qabbmqU86rm\n5fe//z1dunRh6dKlrF27lgsuuMDTIVWhCeLgLnh+MPz2iXZ1VfXWGof7njJlCl26dKF///7079+f\nwMBAUlNTSU1NpVevXlxzzTWceuqpXHHFFRQWWn9H3333HQMGDCApKYmpU6c6BphLSEggKSmJXr16\nMWbMGAoKrJL7119/zemnn87AgQOZMGGCo8tnQkICf/zjH0lKSmLIkCGOEXNrGoK8piHFna8fVB0a\n/JlnniExMZHExET+8Y9/OM4vIrz00kuAVbLr1KkTU6ZMOeb6zJgxw/HzA7joootYvHix42eVnJxM\nnz59eOihhwCrO+vixYuZPXs2AwcO5NJLL+XgQWtU6bVr1zJ06FD69u1bZf3IkSO588476d+/P4mJ\niaxcuRKoeSjzE6UJIqwTFOfCuneJjwpmV06Byz8O1cx9cT+8fmHjPr64v8a3a4rhvidPnsz69eu5\n5ppruOOOO6rsX9Nw37/88guTJk3iiSeeaND7T58+nVWrVrFhwwaKioqqDEHh7Mknn2Tt2rWsXbuW\nrl27OtZv3ryZW2+9lU2bNhEWFsa///1viouLmTJlCvPmzWP9+vWUlZXx4osvOo5ZtGgRKSkpZGRk\nsH37drKysnj00Uf59ttv+fnnn0lOTuaZZ55x7B8eHs769euZPn06d911F3B0CPJ169ZVuU41DSle\nkzVr1vD666+zYsUKli9fziuvvOIYq6lbt26Ooda//PJLYmNj633eSrNmzWL16tWsW7eOJUuWsG7d\nOrKzs9mzZw+PP/4469evJykpyTHHxfXXX8/jjz/OunXrqqwHKCwsZO3atfz73/9m6tSpjvOPGjWK\nlStXsmjRIu677z5H0j0RmiC8fSDxctj6NT3CyigureDAYfcPo6tUpfoM9105RDdY/xHPmjWLRx55\nxLEuLS2N8847j6SkJJ588skaxxSaN2+eowRQOcYPWF/Wp512GklJSSxcuLDBYxLFxsYybNgwwBqi\netmyZWzevJkuXbrQo0cPACZPnsz333/vOObss892jPialJTE8uXL2bhxI8OGDaN///68+eabjkHv\nAK666irH808//QRYQ5C7uk6VQ4q7ct999zmuwfbt2wFYtmwZl156KcHBwYSEhHDZZZc5hgfx9/en\nW7dupKSk8NZbbzmGNnfl2WefdZzbeXiRd999l4EDBzJgwABSUlLYuHEjxhhiY2Mdg/RVXp/c3FwO\nHTp0zPrq12HEiBHk5eVx6NAhvv76ax577DH69+/PyJEjqwxlfiJ0qA2AvhNgxYv0z/8e6EJqVgHt\nwgI8HZVqiPMfa9K30+G+q6o+lWZ9ptZctGgRUVFRXH/99cydO5fQ0FDOPfdc5s6dW+d71HX+moYU\nB6sUdMUVVwBWFVN93HDDDTzxxBOUlZXRrl27Gve7++67uffeewEc1Yc7d+7kqaeeYtWqVbRp04Yp\nU6ac0FDgrq51TUOZnygtQQB0HAiRXYlP/wxAx2RSdWqNw33XZvfu3Y7/6iuHqO7ZsyepqamOKre3\n3nrL8V9xJREhNDTUMQvbDz/84Ni/oKCALVu2OPatLPHMmzeP008/Hah5CPKahhSvyfDhw5k/fz6F\nhYUUFBTw0UcfVbnmgwYN4sCBA/Ualba6vLw8goODCQ8PJyMjgy+++AKAyMhI/P39HSWNyusTHh5O\nmzZtjllf/TosW7aM8PBwwsPD6xzK/HhpCQJABPpeif/ix+jkdbV2dVV1ao3DfdemZ8+evPDCC0yd\nOpXevXtzyy23EBAQwOuvv86ECRMoKytj8ODB3HzzzY5jzj77bESEdu3a8fe//52IiAjeeOMNrrrq\nKkdj9qOPPuqoojp48CB9+/bF39/fUcqoaQjyhho4cCBTpkxhyJAhgDWPxYABAxwN2IDji72hCbRf\nv34MGDCAXr16VamKA+vL/7bbbqO0tJRu3brx2muvAVaSv/nmmyksLOSUU06p8rkCAgIYMGAApaWl\njt+LuoYyP27GGLc9gLHAZmAbcH8t+10OGCDZfp0AFAFr7cdLdb3XoEGDzAnJ2mbMQ2HmhVl3mFvn\nrDmxc6kmsXHjRk+HoIwxO3fuNH369HHre8THx5vMzEy3vkdLcNZZZ5lVq1Yd9/Gu/maA1aaG71W3\nVTGJiDfwAnA+0Bu4SkR6u9gvFLgTWFFt03ZjTH/7cXP14xpdVFfoNIgLzVJ2a1dXpZRyaxvEEGCb\nMWaHMaYEeAcY72K/R4DHAc+Pkpd0JfGl2/HK3qxdXZWqp4SEBDZs2ODW90hNTXXcP9KaLV682DEf\ndlNwZ4LoBOxxep1mr3MQkYFArDHmMxfHdxGRX0RkiYgMd7EdEZkmIqtFZHVmZuaJR5x4GRV4cW7Z\nEg4Vlp74+ZTbaSJXqn6O52/FY72YRMQLeAb4g4vN+4A4Y8wA4B7gbRE5pk+YMeZlY0yyMSY5Jibm\nxIMKaUtOuzMY7/UjqVnNZ9IO5VpAQADZ2dmaJJSqgzGG7OxsAgIa1n3fnb2Y0gHnWw472+sqhQKJ\nwGK7X297YIGIjDPGrAaOABhj1ojIdqAHcHyTTjdAWZ8riM24i51bf4D4i939duoEdO7cmbS0NBql\n9KjUSS4gIIDOnTs36Bh3JohVQHcR6YKVGCYBV1duNMbkAo5KRRFZDNxrjFktIjFAjjGmXEROAboD\nO9wYq0PEwEsp+u6PRGybD+dogmjOfH196dKli6fDUOqk5bYqJmNMGTAd+ArYBLxrjEkRkZkiMq72\noxkBrBORtcD7wM3GmBx3xeosICSCZd6DOSXzGyjXdgilVOvl1hvljDGfA59XW/dgDfuOdFr+APjA\nnbHV5peIczk35wfY9h30HOupMJRSyqN0qA0XDrUfwSFCYP17ng5FKaU8RhOEC53bhvNp2WmYzZ/D\nEe3NpJRqnTRBuJAQFcz88mFIaSH85uoWDaWUOvlpgnAhLjKINaYHhUEdYf27ng5HKaU8QhOEC/FR\nQRi8+C36PNi+CPK1n71SqvXRBOFCaIAv0SF+LPEfCaYcUj70dEhKKdXkNEHUIC4yiBUF7aBdIqzT\naialVOujCaIGCVHB1rDfSRMgfTVkb/d0SEop1aQ0QdQgLiqIfXnFFJ96KSCwvuHTMCqlVEumCaIG\nCVHBGANp5ZEQP8y6aU5HDVVKtSKaIGoQH2VNPJ+aVQh9J0D2Vti31sNRKaVU09EEUYP4qGAAUrML\noPd48PaDdTr0hlKq9dAEUYM2Qb6EBviwO6cQAttA9zGw4QOoKPd0aEop1SQ0QdRARIiPCiI1u9Ba\nkTQB8vfDzu89G5hSSjURTRC1iI8KZnd2gfWix1jwD9MRXpVSrYYmiFokRAWRdrCI0vIK8A2AU8fB\nxgVQWuTp0JRSyu00QdQiPjKYsgrD3kN2Qki6AkoOw5YvPRuYUko1AU0Qtajs6rqrsh2iywgIaa+9\nmZRSrYImiFpUdnXdVdkO4eUNiZfD1q+hsEmmyFZKKY/RBFGLtqH+BPh6HS1BgHXTXEUpbFrgucCU\nUqoJaIKohZeXEB8ZfLSrK0CH/hDVXauZlFInPU0QdYiLCjpaxQQgAn2vhF3LIDfNc4EppZSbuTVB\niMhYEdksIttE5P5a9rtcRIyIJDut+7N93GYROc+dcdYmISqI3TmFVFQ4DdSXdIX1rCO8KqVOYm5L\nECLiDbwAnA/0Bq4Skd4u9gsF7gRWOK3rDUwC+gBjgX/b52tycVHBHCmrIONw8dGVkadA58F605xS\n6qTmzhLEEGCbMWaHMaYEeAcY72K/R4DHAadvYMYD7xhjjhhjdgLb7PM1uYTqXV0rJV0JGRsgY6MH\nolJKKfdzZ4LoBOxxep1mr3MQkYFArDHms4Yeax8/TURWi8jqzMzMxom6moTqXV0r9bkUxBvW63Sk\nSqmTk8caqUXEC3gG+MPxnsMY87IxJtkYkxwTE9N4wTnpEB6Aj5dU7ckEEBIDXUdZ7RAVFW55b6WU\n8iR3Joh0INbpdWd7XaVQIBFYLCKpwFBggd1QXdexTcbH24vYyCBrfurqkiZA7h7Ys7zpA1NKKTdz\nZ4JYBXQXkS4i4ofV6Oy4u8wYk2uMiTbGJBhjEoDlwDhjzGp7v0ki4i8iXYDuwEo3xlqruMgga+Kg\n6npdCL5B2litlDopuS1BGGPKgOnAV8Am4F1jTIqIzBSRcXUcmwK8C2wEvgRuM8Z4bKaehCirBGGq\nz0ntHwI9L4CUj6CsxDPBKaWUm/i48+TGmM+Bz6ute7CGfUdWez0LmOW24BogPiqYw0fKyCkoISrE\nv+rGvlfChvfht08h8TLPBKiUUm6gd1LXg2NU1xwX7RBdR0HbPvDpXZC5pYkjU0op99EEUQ/HjOrq\nzNsXrn4HvP3g7SuhILuJo1NKKffQBFEPsZGBiEBqlosSBEBEHEyaC3l7Yd61UHakaQNUSik30ARR\nD/4+3nQMD2S3qyqmSrGD4dIXYfePsOAOqN6grZRSLYxbG6lPJvFRNXR1dZZ4OWRvh0WzILobjLiv\naYJTSik30BJEPcVH1XCzXHUj7oO+E2Hho7DhQ/cHppRSbqIJop7io4LJLighr7i09h1FYNxzEDsU\n5t8CaaubJkCllGpkmiDqKT7S6upar1KEjz9MmgOh7WHuVXBot5ujU0qpxqcJop6OdnWtR4IACI6G\nq9+1ejS9PRGK89wYnVJKNT5NEPVUebNcnQ3VzmJ6wpVvQuZmeH8qlJe5KTqllGp8miDqKdjfh+gQ\n//pVMTnrejZc+DRs+wa++ot7glNKKTfQbq4NkFCfrq6uJN8A2dvgp+chujsMuanxg1NKqUamJYgG\niIsKqn8bRHXnzrRGfv3ij7D128YNTCml3EATRAMkRAWzP6+Y4tLjGHncyxsuewXa9YH3puhc1kqp\nZk8TRANUNlTXOuRGbfxD4Kp54Bds9WzKP9CI0SmlVOPSBNEADe7q6kp4J2v014JM6x6J0qJGik4p\npRqXJogGSKicF+J4GqqddRwAl70M6ath/q1QUdEI0SmlVOPSBNEAEUF+hAX4HF9Ppup6j4NzZkDK\nh7D4/078fEop1ci0m2sDJUQHn1gVk7Nhd1ndX79/AnwDrddemrOVUs2Dfhs1UHxUIyYIEbjwWeg9\nHr57GOZO1BnplFLNhiaIBoqPDCL9UBGl5Y3UbuDjBxPehAuegh2L4aVhkPpD45xbKaVOgCaIBoqP\nCqK8wpB+sBF7H4lYd1f/7lurqunNi2DJk1BxHPdbKKVUI3FrghCRsSKyWUS2icj9LrbfLCLrRWSt\niCwTkd72+gQRKbLXrxWRl9wZZ0MkRFtdXRulobq6Dv3g999bM9MtehTeuhQOZzT++yilVD24LUGI\niDfwAnA+0Bu4qjIBOHnbGJNkjOkPPAE847RtuzGmv/242V1xNpRjXojjvVmuLv6h1h3X456HPSut\nKqftC93zXkopVQt3liCGANuMMTuMMSXAO8B45x2MMc6TJAQDxo3xNIqYUH8Cfb1JzXJTggCrymng\ndTBtEQRFwVuXwXczdbhwpVSTcmeC6ATscXqdZq+rQkRuE5HtWCWIO5w2dRGRX0RkiYgMd/UGIjJN\nRFaLyOrMzMzGjL1GImLNT53jhiqm6tqeCjctggHXwtKnrbaJ3DT3v69SStEMGqmNMS8YY7oCfwL+\naq/eB8QZYwYA9wBvi0iYi2NfNsYkG2OSY2Jimizm+KggUhurq2td/IJg/PNWtdP+9fDSmbD5y6Z5\nb6VUq+bOBJEOxDq97myvq8k7wCUAxpgjxphse3kNsB3o4aY4GywhKpjdOYVUVDRhjVjfK2HaEgjv\nbN0v8dUDUFbSdO+vlGp1ak0QInKt0/Kwatum13HuVUB3EekiIn7AJGBBtXN0d3p5IbDVXh9jN3Ij\nIqcA3YEddbxfk4mLCqKkrIL9ecVN+8bR3eDGb2HwTdbkQ6+PhYOpTRuDUqrVqKsEcY/T8nPVtk2t\n7UBjTBkwHfgK2AS8a4xJEZGZIjLO3m26iKSIyFr7vSbb60cA6+z17wM3G2Ny6v44TSMhyo1dXevi\nGwAXPgVX/heytsFLI2Djx00fh1LqpFfXWExSw7Kr18cwxnwOfF5t3YNOy3fWcNwHwAd1nd9T4iq7\numYXckZXDwXRe7x138T7U+Hd66H/NTDmUQiK9FBASqmTTV0lCFPDsqvXrUbHiEB8vaXpGqpr0iYB\nbvgShv8B1s2D55Nh7VwwrfZHo5RqRHUliF4isk5E1jstV77u2QTxNUveXkJsZNCJzwvRGHz8YPSD\n8PulENUN5t8M/x0H2ds9HZlSqoWrq4rp1CaJogWKjwxqvFFdG0O73lZp4uc34JsZ8O/TYcS9MOxO\n8PH3dHRKqRao1hKEMWaX8wPIBwYC0fbrVssa9rsA05yqc7y8IHkqTF8JvS6ARbPgpeGw60dPR6aU\naoHq6ub6qYgk2ssdgA1YvZfeEpG7miC+Zis+KoiCknKyC5rhvQih7WHCG3D1e9ac16+fDwtuh8Jm\n0xFMKdUC1NUG0cUYs8FevgH4xhhzMXAadXRzPdlVdnVtFu0QNekxBm5bDmfcAb/MgReGwLr3tBFb\nKVUvdSWIUqfl0dhdVo0xh8sHKOEAACAASURBVIFGmjGnZYqPsrq6unXQvsbgFwxjHoHfL4GIOPjw\nd/C/yyCn2dx3qJRqpupKEHtE5HYRuRSr7eFLABEJBHzdHVxz1rlNEF4Cu9w17Hdja58EN35jzVy3\nZ5XViL30aR2uQylVo7oSxI1AH2AKMNEYc8hePxR43Y1xNXt+Pl50jAhs3lVM1Xl5WzPXTV8J3cdY\nQ4i/fBbsXuHpyJRSzVCt3VyNMQeAYybrMcYsAha5K6iWIj6qmXV1ra+wjjDxLdj8BXx2L8weAz0v\ngAHXWYnDu67ez0qp1qDWbwIRWVDbdmPMuNq2n+zio4L5Yv0+T4dx/HqeDwnDYdmz8PN/YfPnENIO\n+l0FA6+HKE+NI6KUag7q+lfxdKxJf+YCK6jH+EutSUJUEAcLS8ktKiU8sIU2yfiHwOi/wcj7YevX\n8PNb8OO/4Id/QPwwq1TRe7w1L4VSqlWpqw2iPfAXIBH4J3AukGWMWWKMWeLu4Jq7uEirq+vulljN\nVJ23L/S6EK5+B+7eaA3fcXifNXTH0z3hk7sg/WftIqtUK1LXndTlxpgvjTGTsRqmtwGL6zEXRKuQ\nEG13dW1JDdX1EdbBGgDw9p9hymdW+8Sv78ArZ1sz2i1/SW+6U6oVqHNGORHxF5HLgP8BtwH/Aj5y\nd2AtgWPY75bS1bWhRCDhTLjsP3DvZrjwGfDygS//ZJUq3rsBti+EilZ9S4xSJ626Gqn/i1W99Dnw\nsNNd1QoI8vOhbag/qVknWQnClYBwGHyj9di/3mqrWDcPUj6E8DgYcA30v9q6GU8pdVKQ2gabE5EK\noPLbz3lHAYwxJsyNsTVIcnKyWb16dZO/75Uv/QTAuzef3uTv7XGlxfDbp/DLW7BjMSBwylnQ/1o4\n9SLwDfR0hEqpOojIGmNMsqttdd0HUWcVVGsXFxXE0q2Zng7DM3wDIOkK63FwF/w6F9bOsYbz8A+3\n1g+4FjoOsKqrlFItiiaAE5QQFURG3hGKSso9HYpntYm3usre8StcvwB6nGcli1fOhhfPgJ9egIIs\nT0eplGoATRAnKM4e1fWkbahuKC8vq5rp8lfgD5vhometqqav/mI1bM+7FrZ8BeVlno5UKVUHHVPh\nBCVEHe3q2rN9qIejaWYCI6wJjJKnwoFN8Mv/rO6ymz6BkPbQb5JVBRXd3dORKqVc0BLECUqIDsbH\nS/hyw35Ph9K8tT0VzpsFf/gNJr0NnQbCj8/B88nw2hj44Z/WKLM6uqxSzYZbSxAiMhbrDmxv4FVj\nzGPVtt+MdW9FOdZ0ptOMMRvtbX/GGk22HLjDGPOVO2M9XmEBvtw6siv/WriNC5I6cG7vdp4OqXmr\nvGO714VwOAPWvQNr58I3D1rbfQKhc7I1zEf86dB5sDWnhVKqydXazfWETiziDWzBGp4jDVgFXFWZ\nAOx9wowxefbyOOBWY8xYEemNNf7TEKAj8C3QwxhTY0uwp7q5ApSUVTD+hR/IPHyEb+4eQZtgP4/E\n0aIdzoDdP1mPXT9a91pgrBvzOvS3kkXcGRA3FIIiPR2tUieN4+7meoKGANuMMTvsIN4BxgOOBFGZ\nHGzBHL3XYjzwjjHmCLBTRLbZ5/vJjfEeNz8fL56e0I9xzy/joQUp/OuqAZ4OqeUJbQd9LrEeAMW5\nsGellSx2/wQr/mNVSQG07Q1xp0P8GdZzeCfPxa3UScydCaIT1kiwldKw5rKuQkRuA+4B/IBRTscu\nr3bsMd8CIjINmAYQF+fZO3h7dwzjjtHdeeabLZyf2J7zkzp4NJ4WLyAcup9rPcC6KS99Dez+EXb9\nZN3Fvfo1a1tEPHQ9G3qcb/Wg0hv0lGoUHu/FZIx5AXhBRK4G/gpMbsCxLwMvg1XF5J4I6++WkV35\nZmMGD8zfwOAukUSH+Hs6pJOHbwAkDLMeYHWTzVhvJYtdP8D692HNG1YbRtezrbkuup9nlUyUUsfF\nnQkiHYh1et3ZXleTd4AXj/PYZsHX24unr+zHRf9axt/mb+Df1wxE9A5i9/D2se7Q7jgATr8Vyo5A\n6lLY/CVs+dKa/Aig0yArWfQ4H9r10Tu6lWoAd3ZzXQV0F5EuIuIHTAKqzFAnIs4d4C8EttrLC4BJ\n9kiyXYDuwEo3xtpoerQL5e5ze/DFhv18sq4FzzbX0vj4Q7dz4MKn4K71cPMyOPuv1raFj8JLw+Af\nfeHz+6wRaLU7rVJ1clsJwhhTZs8b8RVWN9fZxpgUEZkJrDbGLACmi8g5QClwELt6yd7vXawG7TLg\nttp6MDU3Nw3vwlcp+3nw4w0MPSWStqEBng6pdRGB9knW46z74PB+6+7tLV9ao9CufBn8QqHbKGuu\ni+5jtGeUUi64rZtrU/NkN1dXth3I58J/LWV49xheuX6QVjU1F6VFsGMJbPnCqo7K3w/iZXWlTRhm\n3X8RNxQC23g6UqWaRG3dXDVBuNGrS3fw6GebeObKflw2sLOnw1HVVVTAvrVW6SJ1KaStgvISQKBd\notWNNmGYdf9FSIyno1XKLTRBeEh5hWHif35ic8Zhvrn7LNqHa1VTs1bZlXbXD9Zjz0ootQdhjO5h\n391t96QK6+jZWJVqJJogPCg1q4Cx//yeoadE8fqUwVrV1JKUl8LetUcTxu7lcMS+t7NNwtGEEX+G\n9Vp/tqoF0gThYW/8sJMZn2zkicv7cuXg2LoPUM1TRTlkbIBUO2Hs+hGKcqxtPoFWqSKsI4R1crHc\nCYKirOHQlWpGNEF4WEWF4epXl7MhPY+v7h5Bpwi90/ekUFEBWZutZJGzE/LSIW/v0Uf1jnfefhDa\nwXUCie4OUd2t+zuUakKaIJqBPTmFnPeP7xkY14a3bhyiVU0nu4pyKMisljRcLJc73Y/hE2DdzNeh\nH7TvCx36Qts+1l3kSrmJpwbrU05iI4P4ywWn8tf5G5izYjfXDo33dEjKnby8IbS99eg0yPU+xkBh\nNuSmQeZvsG8d7F8H6z+A1bOtfcQbYnraCaOflTTaJ1ljVSnlZlqCaELGGK57bSU/7z7IV3eNIDYy\nyNMhqebIGDiYaiWLyqSxb511z0alNglHSxnt+1kTMoV10jYO1WBaxdSMpB8qYuyz39O7YxhzbxqK\nl5dWNal6OpxhJ4tfjyaNgzuPbvcJgMiuENUVorpVfQRFai8r5ZJWMTUjnSIC+dtFvfnjB+v470+p\nTBnWxdMhqZYitB2EOg2BDta8Gfs3WI3l2dshexsc2GgNVlhRdnS/gIhqSaPr0WedsU/VQBOEB0xI\n7sznG/bx2Je/MbJnWxKi9Q9UHaeA8KrDoFcqL4VDu62EUZk4srdB6jJrmldnoR0hpofVIN6ut9VQ\nHtNL59VQWsXkKftzixnz7BJ6tAtl3u9Px1urmlRTKSmEnB1Hk0b2NjiwyWooLyu29hEviDzFmr2v\nXaKVONr2hjZdtJ3jJKNVTM1Q+/AAZozrwz3v/srrP+zkd8NP8XRIqrXwC4L2idbDWUW5dT/HgRTI\nqHxsgE2f4JgN2DfIahBva5c0Kp+Do5v8Yyj30xKEBxljuOm/a/h+ayYf3zaMUzuEeTokpY5VUmCV\nLjJSIGPj0QRSmH10n4BwCOts3fQX3sn1sp/22muOtBdTM3bgcDEX/msZRSXlPDuxP+f21ikyVQtg\nDOQfsJPFRqtbbt5eyEuD3HQozDr2mMA21RKH/QjvZM0rHt7Zun9ENSlNEM3c3kNF3Py/NaxLy+XO\n0d25c3R37f6qWrbSYji810oWefaj+nLlOFaVvP3t3lWuuulGaTddN9EE0QIUl5bz1/kbeH9NGuec\n2pZnJvYnLMDX02Ep5T4lhXB4n3Un+cGdVXtc5eyEitKj+waEu+6mG9kV/EM89xlOApogWghjDG8t\n38XMTzYSFxnEy9cPolvbUE+HpVTTKy+D3N1HE0bW1qMJJC+t6r6hHaxqq4Bw636PgHDrERhRbV2E\n07pw8NZ/wEATRIuzYkc2t739M8WlFTx9ZT/O69Pe0yEp1Xy46qabn2HdNFh0yHouPlT1RkFXfIOP\nJpKgKCvRhLa3E06Ho69D2p/UAyZqgmiB9h4q4pb/reHXtFzuGNWNu87poe0SStWXMdZsgMW51RKH\nnTyqrD8EBVlWddfh/VB+5NjzBUa6SCDtndZ1hJC2LbKRXe+DaIE6RgQy7/en87f5G/jXwm2k7M3j\nmYn9CQ/UYrFSdRKxhhDxC27Y9LDGQNFBO1nsgzw7aVQmj8N7raFM8jPAVFQ91sun6nwfzj21Kntr\nBce0qCSiJYhmzhjD/5bv4uFPNhIbGcTL1w2iezttl1DKoxzzfew9mkxy053m+rB7alUvjXj5WKWN\nygmjHEmko7W+coj4Jmwf8VgVk4iMBf4JeAOvGmMeq7b9HuB3QBmQCUw1xuyyt5UD6+1ddxtjxtX2\nXidrgqi0cmcOt85ZQ1FJOU9f2Z+xidouoVSzZgwU5liN6nl7rd5aVSaOqiGJIFZJI7S9nTjsKixH\nu4j9aKQRej2SIETEG9gCnAukAauAq4wxG532ORtYYYwpFJFbgJHGmIn2tnxjTL37r53sCQJgX24R\nN//vZ37dc4jbR3Xjbm2XUKplq5w0Km/v0SqsvH1HSyWV1Vyubjz09j/aDtI5Gc6bdVwheKoNYgiw\nzRizww7iHWA84EgQxphFTvsvB651YzwtXofwQOZNG8qDH2/guYXb2JCeyz8mDdB2CaVaKhFrHKvg\naGvyp5qUHbHaPZyThyOp7LNKKm7gzgTRCdjj9DoNOK2W/W8EvnB6HSAiq7Gqnx4zxsyvfoCITAOm\nAcTFxZ1wwC1BgK83j1/el6TOETy8IIVLXvhB2yWUOtn5+ENEnPVoQs1i3F4RuRZIBp50Wh1vF3uu\nBv4hIl2rH2eMedkYk2yMSY6JiWmiaD1PRLhuaDxzpw3lcHEZl7zwA2/9lEppeUWdxyqlVH25M0Gk\nA7FOrzvb66oQkXOAB4BxxhhHa40xJt1+3gEsBga4MdYWaXBCJJ/efiZJncP528cpnPvMEj5bt4+T\npWeaUsqz3JkgVgHdRaSLiPgBk4AFzjuIyADgP1jJ4YDT+jYi4m8vRwPDcGq7UEe1Dw9g7k1DmT0l\nGX8fb257+2cueeEHftzmolFLKaUawG0JwhhTBkwHvgI2Ae8aY1JEZKaIVHZZfRIIAd4TkbUiUplA\nTgVWi8ivwCKsNghNEDUQEUb1asfndw7nqQn9yDx8hKtfXcH1s1eSsjfX0+EppVoovVHuJFRcWs7/\nlu/i+UXbOFRYyiX9O/KHMT2JjdQJW5RSVelYTK1UblEp/1myndk/7KS8wnDNafHcPqobUSH+ng5N\nKdVMaIJo5TLyivnHt1t5d/UeAn29mTbiFG48swvB/joUl1KtnSYIBcC2A/k89dVmvkzZT3SIP3eO\n7sakIXH4ejeL3s5KKQ+oLUHoN0Mr0q1tCC9dN4gPbz2DU2KCHV1jP/l1LxUVJ8c/CkqpxqMliFbK\nGMPizZk8/uVv/Lb/MHGRQVyZ3JkrBsXSPvzknRxFKVWVVjGpGpVXGD5bv4+5K3bz045svARG9Ihh\nYnIso09th5+PFjKVOplpglD1siu7gPdWp/H+mjT25xUTGezHpQM6MXFwLD10rCelTkqaIFSDlFcY\nvt+aybur9vDtpgxKyw39YyOYODiWi/p2IDRAR49V6mShCUIdt+z8I3z0Szrvrt7Dlox8An29uSCp\nAxMHxzI4oQ3SCBOWKKU8RxOEOmHGGNbuOcS7q9P45Ne95B8po0t0MBOSO3PFwM60DdOGbaVaIk0Q\nqlEVlpTx+fr9vLtqDytTc/D2Ek7rEsk5p7bjnFPbERelQ3oo1VJoglBusyMznw9+TuPrlAy2HsgH\noEe7EEbbyaJ/bATeOi2qUs2WJgjVJHZlF/DtpgN8tymDFTtzKK8wRAX7MapXW0af2o7h3aN1eA+l\nmhlNEKrJ5RaVsmRLJt9uzGDR5gMcLi7Dz8eLM7pGcc6p7Rh9als6hAd6OkylWj1NEMqjSssrWJWa\nw7cbD/Dtpgx25xQCkNgpjNG9rKqoxE5h2iNKKQ/QBKGaDWMM2w7k8+0mK1n8vPsgxkB0iB/DukVz\nZrdozuweraULpZqIJgjVbGXlH2Hx5kyWbs3kh21ZZOWXANA1Jpjh3WMY1i2aoadE6s15SrmJJgjV\nIlRUGDZnHGbZ1iyWbctixc5siksr8PYSBsRGMKxbNMO7R9MvNkKHKFeqkWiCUC3SkbJy1uw6yA/b\nsli2NYt16bkYAyH+Pgw9JdJRHdU1JkTbL5Q6Tpog1EnhUGEJP23PZum2LH7YlsWubKuxu31YAIMS\n2tCnYxiJHcPp0zFMp1VVqp5qSxDaKV21GBFBfpyf1IHzkzoAsCenkGXbrOqodWmH+GzdPse+HcID\n6GMni8RO4SR2CqN9WICWNJRqAC1BqJNGbmEpKftySUnPY8PeXFL25rE9M5/KX/HIYD9HwqgsbcRF\nBuGld3qrVsxjJQgRGQv8E/AGXjXGPFZt+z3A74AyIBOYaozZZW+bDPzV3vVRY8yb7oxVtXzhQb6c\n0TWaM7pGO9YVHCnjt/15pOzNY0N6LhvS83h16Q5Ky62sEervw6l2skjqbD2fEhOiw4MohRtLECLi\nDWwBzgXSgFXAVcaYjU77nA2sMMYUisgtwEhjzEQRiQRWA8mAAdYAg4wxB2t6Py1BqPo6UlbO1ox8\nNqRbpYz16bn8tj+P4tIKAAJ9vendMYykTkerqLq3DcFHe06pk5CnShBDgG3GmB12EO8A4wFHgjDG\nLHLafzlwrb18HvCNMSbHPvYbYCww143xqlbC38fbbpcId6wrK69ge2YBG9JzWZ+eS8reXN5dvYfC\nknL7GC96dQgjqZNVykjsFE6PdqE6Jas6qbkzQXQC9ji9TgNOq2X/G4Evajm2U/UDRGQaMA0gLi7u\nRGJVrZyPtxc924fSs30olw/qDFgz6+3MKiBlby7r03LZsDeXj3/Zy/+W7wbA11vo2T6UpE7hdGsb\nSlxkEPFRQcRFBhHg6+3Jj6NUo2gWvZhE5Fqs6qSzGnKcMeZl4GWwqpjcEJpqxby9hG5tQ+jWNoTx\n/a3/TyoqDLtzClmfbiWMlPQ8vtiwn0OFe6oc2y7Mn7jIIOIigx1JIy4qiPjIICKD/bQ3lWoR3Jkg\n0oFYp9ed7XVViMg5wAPAWcaYI07Hjqx27GK3RKlUA3h5CQnRwSREB3Nxv46ANb7UwcJSdmUXsDun\nkN3Zheyyn3/YlsUHPxdXOUeIvw+xkVayiI8KIjbSTiCRQXSMCNRqK9VsuDNBrAK6i0gXrC/8ScDV\nzjuIyADgP8BYY8wBp01fAX8XkTb26zHAn90Yq1LHTUSIDPYjMtiPAXFtjtleXFrOnpxCdmUXWgkk\np5Bd2QVsPXCYhb8doKS8wrGvl1g3/nW2E0ZsmyBiIwOt5cggYkL8tVuuajJuSxDGmDIRmY71Ze8N\nzDbGpIjITGC1MWYB8CQQArxnF7l3G2PGGWNyROQRrCQDMLOywVqplibA15vu7ULp3i70mG0VFYb9\necXssRPHnoNFpNnLS7dmkpF3pMr+fj5edG4TeEzy6BQRRMeIAK2+Uo1Kb5RTqhkrLi0n/VARu3MK\nSbMTiCOZ5BSSV1xWZX9/Hy86RQTSMSKQjhEB9nOgY12H8ABtQFdV6FAbSrVQAb7edI0JoWtMiMvt\nuUWl7MkpJP1QEXsdj2LSDxWxZEsmBw4fofr/gFHBflUSSKeIQDqEB9IhIoAO4QG0DQ3QGwUVoAlC\nqRYtPNCX8Gr3dDgrKasgI6+4SgJJP1TM3kNF7MwqYNnWLArsez0qeXsJbUP96RAeYCWO8ADah1vJ\npH14AB3DA4kJ9dck0gpoglDqJObn40Ws3cDtijGGvKIy9uUVse9QMXtzi9ifW8zeQ8Xszyti0748\nvvstw3GXeSVvL6FdqD8d7KTRLjSAmFB/YkL9iQ7xcyxHBWsiack0QSjViokI4UG+hAf50qt9mMt9\njDHkFpU6ksbeQ8VWEsm1kkpKei6LDx84piRind+q0ooOsRJGTEhlEvF3SijWc0Sgr/bQamY0QSil\naiUiRAT5ERHkR++OrpMIWAMjZuUfISv/CJmHnR75JfbzEXZkFpCZf4SSsopjjvfxkiqJI8Z5udq6\nYH/96moKepWVUo0i2N+HYH8f4qOCa93PGENecRmZh61kcuDwEbLsBFKZVPbnFrM+PZfs/CNUuOho\nGeTnfUyJJCrEKqlE289R9nKIv492/T1OmiCUUk1KRKzG9UBfurV13TurUnmFIaegxJFMMqslkszD\nR9iScZgft2eTW1Tq8hz+Pl5VEkhUsB/RodZzZTtJVIh1o2NEkC/+PtoNuJImCKVUs+XtJY7qpbqU\nlFVwsNBKJtkFJWQdPkJ2wRGy8kvsqq8SMvKKSdmbS3Z+CWWuiiZYQ6G0CfYlMtifyCBf2gT7ERnk\nR5tgP6KCrefIYD/aBFnP4YG+J21DvCYIpdRJwc/Hi3ZhAbQLC6hz38qG98rkcbCghOyCEg4WlJBT\nWPlsbd+SkU9OQQlFpcc2woPVEB9hl4jCg/yICPQlIsjXWuf8OsiX8EC/o9sCfZv9HCOaIJRSrY5z\nw3td1VyVikrKOVhYQk5BieO58nGosJRDRaUcKrS27cwq4FBhCYePlB1zo6KzEH8fR3VbWKAPYQG+\nhAX62s/Or32qrg/0JcTPx+29vjRBKKVUPQT6eRPoZw1ZUl/lFYbDxaVVEkhukf26sJRDRVZyySsq\nJa+4lF3ZheQVW69ddRt2JmJNmRsW6Ev/2Aiev3rgiX7EY2iCUEopN/H2OlpSaaiy8goOF5eRV1xq\nPdtJJK+ozJFE8uz17cPrrlY7HpoglFKqGfLx9qKN3SjuKc27hUQppZTHaIJQSinlkiYIpZRSLmmC\nUEop5ZImCKWUUi5pglBKKeWSJgillFIuaYJQSinlkpjaBgppQUQkE9h1AqeIBrIaKRx30PhOjMZ3\nYjS+E9Oc44s3xsS42nDSJIgTJSKrjTHJno6jJhrfidH4TozGd2Kae3w10SompZRSLmmCUEop5ZIm\niKNe9nQAddD4TozGd2I0vhPT3ONzSdsglFJKuaQlCKWUUi5pglBKKeVSq0oQIjJWRDaLyDYRud/F\ndn8RmWdvXyEiCU0YW6yILBKRjSKSIiJ3uthnpIjkisha+/FgU8XnFEOqiKy333+1i+0iIv+yr+E6\nEWn8eRBrjq2n07VZKyJ5InJXtX2a9BqKyGwROSAiG5zWRYrINyKy1X5uU8Oxk+19torI5CaM70kR\n+c3++X0kIhE1HFvr74Ib45shIulOP8MLaji21r93N8Y3zym2VBFZW8Oxbr9+J8wY0yoegDewHTgF\n8AN+BXpX2+dW4CV7eRIwrwnj6wAMtJdDgS0u4hsJfOrh65gKRNey/QLgC0CAocAKD/6892PdBOSx\nawiMAAYCG5zWPQHcby/fDzzu4rhIYIf93MZebtNE8Y0BfOzlx13FV5/fBTfGNwO4tx4//1r/3t0V\nX7XtTwMPeur6neijNZUghgDbjDE7jDElwDvA+Gr7jAfetJffB0aLiDRFcMaYfcaYn+3lw8AmoFNT\nvHcjGw/811iWAxEi0sEDcYwGthtjTuTu+hNmjPkeyKm22vn37E3gEheHngd8Y4zJMcYcBL4BxjZF\nfMaYr40xZfbL5UDnxn7f+qrh+tVHff7eT1ht8dnfHVcCcxv7fZtKa0oQnYA9Tq/TOPYL2LGP/QeS\nC0Q1SXRO7KqtAcAKF5tPF5FfReQLEenTpIFZDPC1iKwRkWkuttfnOjeFSdT8h+npa9jOGLPPXt4P\ntHOxT3O5jlOxSoSu1PW74E7T7Sqw2TVU0TWH6zccyDDGbK1huyevX720pgTRIohICPABcJcxJq/a\n5p+xqkz6Ac8B85s6PuBMY8xA4HzgNhEZ4YEYaiUifsA44D0Xm5vDNXQwVl1Ds+xrLiIPAGXAnBp2\n8dTvwotAV6A/sA+rGqc5uoraSw/N/m+pNSWIdCDW6XVne53LfUTEBwgHspskOus9fbGSwxxjzIfV\ntxtj8owx+fby54CviEQ3VXz2+6bbzweAj7CK8s7qc53d7XzgZ2NMRvUNzeEaAhmV1W728wEX+3j0\nOorIFOAi4Bo7iR2jHr8LbmGMyTDGlBtjKoBXanhfT18/H+AyYF5N+3jq+jVEa0oQq4DuItLF/g9z\nErCg2j4LgMreIlcAC2v642hsdn3la8AmY8wzNezTvrJNRESGYP38mjKBBYtIaOUyVmPmhmq7LQCu\nt3szDQVynapTmkqN/7l5+hranH/PJgMfu9jnK2CMiLSxq1DG2OvcTkTGAn8ExhljCmvYpz6/C+6K\nz7lN69Ia3rc+f+/udA7wmzEmzdVGT16/BvF0K3lTPrB62GzB6t3wgL1uJtYfAkAAVrXENmAlcEoT\nxnYmVlXDOmCt/bgAuBm42d5nOpCC1SNjOXBGE1+/U+z3/tWOo/IaOscowAv2NV4PJDdxjMFYX/jh\nTus8dg2xEtU+oBSrHvxGrHat74CtwLdApL1vMvCq07FT7d/FbcANTRjfNqz6+8rfw8qefR2Bz2v7\nXWii+N6yf7fWYX3pd6gen/36mL/3pojPXv9G5e+c075Nfv1O9KFDbSillHKpNVUxKaWUagBNEEop\npVzSBKGUUsolTRBKKaVc0gShlFLKJU0QqkUTkdPEGgX3VxHZJCIv23ejNysi8jsRWSoiq0Vkhqfj\nUao+fDwdgFInKAC4ztg3JInILcCrWDdGNQsiciPWyLYXGWNyPR2PUvWlJQjVohljlhinu1WNMS8C\nPUSkqxw790N65X/vItJfRJY7zXnQRkR8RGSViIy09/k/EZllLz9ob9tgl1KOGeVXRBJEZKF9zu9E\nJM7eNA1r2Idl9nv2FREvseZ5iLGP9RJr3oIYEVksIsn2+iki8ry9HCMiH9hxrBKRYfb6GSJyr1Mc\nnzp9hnyn9UtF5FN7hqyCAgAAAuxJREFUOdJ+n1/FmjNhcWP8PNTJRROEavFE5D6nJLAW6y7V3vbm\npcaY/saY/sCzTof9F/iTMaYv1l25DxlrBN8pwIsicg7W8NoP2/s/b4wZbIxJBAKxximq7jngTfuc\nc4B/2evbAj8aY5KAv2ANh14B/A+4xt7nHOBXY0wmUIF1R3p1/wSeNcYMBi7HKinV9xpdiDW2WKVr\nsOYw6OcUg1JVaIJQLZ4x5snKJGAngnW17S8i4UCEMWaJvepNrIlfMMakYA3l8Ckw1VhzCQCcLdYs\ng+uBUYCrYcJPB962l9/CGj4FrC/7t+zzLwSiRCQMmA1cb+8zFXjdXk7DGu69unOA5+0kuAAIc2pv\nudspQQ6v9nkFeAD4u9PqcqyJqZSqkbZBqJOK/cXbH9hI1dE8GyIJOIT1nz8iEgD8G2tcqT12NVVA\nA85Xfdh2AOxzZYjIKKyRPCv/k/878KaI3IY1m1zlIHNewFBjTLHzeezarmeNMU/Zrz+t9lZXAYux\n5p6o9BZwvojsx5r3pKkHVFQtgJYgVItm19EPsJe9seYG+NIYs72mY+yG4oMiUvmf9nXAEvscl2FN\n8zkCeE6s+Zgrk0GW/R/7FTWc+keONo5fAyy1l1fYr7HbBrLM0bk+XsWqanrPGFNux/ebMeY0u/rH\nec7sr4HbnT57/5o+oxMv4C6saU6d5WPN9XAdWsWkavD/7d0/SkNBEIDxb0ohx7ELHkWCkCaFsQrY\n2KQIAUERcg1P4BGEFEFTeApvMBa7kBSr71X5g9+vXPYNbDXMzmPWBKFz9wk8RcSaMrUzgHGP70bA\nY0RsKBXHPMq7EEtgnJlfwAp4ycxvyrsDH5SR2++/xLwFbmrMa+Curj8Aw7q+YDfqG0p1MGB3vfSX\nKXBZm+BbypTaLhfAaz3Dvhmwycy3HjH0TznNVTqi+rfSc2ZedW6WDswehHQkEXEPTPCKRyfKCkKS\n1GQPQpLUZIKQJDWZICRJTSYISVKTCUKS1PQDb4cUuB1SEdoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Средняя ошибка:  107160.0\n",
            "Средняя цена:  530277.0\n",
            "Процент ошибки: 20.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCHQ_1ugNctW",
        "colab_type": "text"
      },
      "source": [
        "**1.2** создаем базу данных без учета **модели** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ3t1fH1N7zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okVrzhGQOoxI",
        "colab_type": "code",
        "outputId": "07ec0fd3-50ad-4662-9ca7-384d7f005ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "#Создаём сеть без \"модели\"\n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.4719 - val_loss: 0.4540\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.2935 - val_loss: 0.3758\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.2489 - val_loss: 0.3396\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.2253 - val_loss: 0.3161\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.2096 - val_loss: 0.2997\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1979 - val_loss: 0.2862\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 174s 3ms/sample - loss: 0.1889 - val_loss: 0.2768\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 174s 3ms/sample - loss: 0.1816 - val_loss: 0.2675\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 174s 3ms/sample - loss: 0.1758 - val_loss: 0.2606\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1707 - val_loss: 0.2550\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1659 - val_loss: 0.2494\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1620 - val_loss: 0.2432\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1585 - val_loss: 0.2397\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1554 - val_loss: 0.2354\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1525 - val_loss: 0.2313\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1498 - val_loss: 0.2280\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1471 - val_loss: 0.2261\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1450 - val_loss: 0.2225\n",
            "Epoch 19/20\n",
            "28580/60000 [=============>................] - ETA: 1:29 - loss: 0.1804"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQyq08osRUCZ",
        "colab_type": "text"
      },
      "source": [
        "**1.3** Создаем базу без учета типа **кузова** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0g-uqz7RVKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OOlWf4zRteh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "78cae870-0c93-4138-a6fb-68430147d16f"
      },
      "source": [
        "#Создаём сеть без \"кузова\"\n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 308s 5ms/sample - loss: 0.5149 - val_loss: 0.4799\n",
            "Epoch 2/30\n",
            " 1220/60000 [..............................] - ETA: 4:46 - loss: 0.2559"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e9d66733b9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP9GS5uSSIeV",
        "colab_type": "text"
      },
      "source": [
        "**1.4** Создаем базу без учета типа **КПП** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4E_MPKHSJM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzeNUP-1SJ8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "f09d1c03-2106-47ad-aa71-66ee2c1d9ab4"
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 6800/60000 [==>...........................] - ETA: 4:28 - loss: 0.7763"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzEEhwSgSenm",
        "colab_type": "text"
      },
      "source": [
        "**1.5** Создаем базу без учета типа **топлива** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe7lkujtSyf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78lkq8kESyH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c7679292-cbfc-40d9-8329-caa5fe98aa7a"
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 4700/60000 [=>............................] - ETA: 4:42 - loss: 0.8714"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcm-wGZUSziV",
        "colab_type": "text"
      },
      "source": [
        "**1.6** Создаем базу без учета типа **обем двигателя** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIVjL336TI0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7UUsjIsTIfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "b7a16b50-e1d8-42b9-fdc9-ab1e1aa77bad"
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 5300/60000 [=>............................] - ETA: 4:43 - loss: 0.8028"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo72bKhCTJqB",
        "colab_type": "text"
      },
      "source": [
        "**1.7** Создаем базу без учета типа **мощности двигателя** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOPZGR5MUfta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] \n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Md1Ydm1UfGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "685fa188-a13e-4714-a4ac-354ba8d4f1d1"
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни проценt ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 6220/60000 [==>...........................] - ETA: 4:34 - loss: 1.0294"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7tMcrVVbxR",
        "colab_type": "text"
      },
      "source": [
        "**1.8** Создаем базу без учета **года выпуска** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nA44oBBVnaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESHcBodEVn79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "73a18e5e-8ec8-4685-cc16-32d9d9a047b4"
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 6920/60000 [==>...........................] - ETA: 4:32 - loss: 1.0975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd0gGLSJUhCq",
        "colab_type": "text"
      },
      "source": [
        "**1.9** Создаем базу без учета **пробега**  автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbCwhaI3UwFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OshvRh2YUwlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "cb25354f-9290-4d91-c882-1bd155025d1e"
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 2060/60000 [>.............................] - ETA: 5:13 - loss: 0.7004"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ithJPd9vVrbL",
        "colab_type": "text"
      },
      "source": [
        "**1.10** Создаем базу без учета **марки** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W04W30gLz5qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# создаем базу данных\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_4FIGczby-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le_l86n_7o-R",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJih6MBYcch6",
        "colab_type": "text"
      },
      "source": [
        "**2** Отключаем нормализацию входных данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C5VMDR34bnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Задаем числовые параметры без нормализации\n",
        "\n",
        "years = cars['year']\n",
        "mileages = cars['mileage']\n",
        "volumes = cars['volume']\n",
        "powers = cars['power']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAJHKmkn5kv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# создаем базу данных\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVJmYTz-5izu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "36b65c70-c52e-41e8-ac12-fff91fd7e00b"
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            "23280/60000 [==========>...................] - ETA: 3:06 - loss: 313.5793"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JacvA2Ps7cLu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YIiui66-JDY",
        "colab_type": "text"
      },
      "source": [
        "**3** Проверяем влияние на ошибку, операции преобразования входных данных \"года выпуска автомобиля\" в формат +ohe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlS2yP9n7dZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Запоминаем числовые параметры\n",
        "#И нормируем\n",
        "years = preprocessing.scale(cars['year'])\n",
        "mileages = preprocessing.scale(cars['mileage'])\n",
        "volumes = preprocessing.scale(cars['volume'])\n",
        "powers = preprocessing.scale(cars['power'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNKJCyZP5iBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        to_ohe(car[3], years(_id)) + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5zoT1m6ERBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "f4c1bc9c-bfc3-4dce-b684-e65dd9febbbf"
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 312s 5ms/sample - loss: 0.5507 - val_loss: 0.5121\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 312s 5ms/sample - loss: 0.3287 - val_loss: 0.4059\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 311s 5ms/sample - loss: 0.2691 - val_loss: 0.3593\n",
            "Epoch 4/30\n",
            "35800/60000 [================>.............] - ETA: 2:00 - loss: 0.2505"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e9d66733b9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "airKXGWsBoKL",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAOvZP2QByq8",
        "colab_type": "text"
      },
      "source": [
        "**4**`**Архитектура сети НС**`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwM76wfEC0HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr =  to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLlRChqDCIy4",
        "colab_type": "text"
      },
      "source": [
        "**4.1** добавляем  слой Dropout в НС."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7pQU_wRDei4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "539ZUZvVPanX",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3t3RgjEiGX",
        "colab_type": "text"
      },
      "source": [
        "**4.2** добавляем слой Batch Normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sGuAEBZEiaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLRxXecIPfMU",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHqiPqVtExUL",
        "colab_type": "text"
      },
      "source": [
        "**4.3** меняем активационную функцию elu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd17e_RvFEfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='elu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='elu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzG2SdanPh06",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuDh8OdDFGEI",
        "colab_type": "text"
      },
      "source": [
        "**4.4** меняем активационную функцию linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aucr8vjoFRi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='linear', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='linear'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0DPSXLGPkpy",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33k-dpgBFeU7",
        "colab_type": "text"
      },
      "source": [
        "**4.5** меняем активационную функцию sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8sgAl2ZFoXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='sigmoid', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbHIJF2qPoWa",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kMwn4LtFo99",
        "colab_type": "text"
      },
      "source": [
        "**4.6** меняем шаг обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5CHavhGF5-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-3\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRTMCIttPqs4",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi8sQIUeF6r6",
        "colab_type": "text"
      },
      "source": [
        "**4.7** меняем размер батча."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkv92AbBGF5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=40,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKOeYD6WPsyE",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMWOk785GGnB",
        "colab_type": "text"
      },
      "source": [
        "**4.8**  меняем число нейронов НС, увеличиваем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsCw2nkzIURU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(4500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUeiEthJPu01",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293pqxTcIVdK",
        "colab_type": "text"
      },
      "source": [
        "**4.9** меняем число нейронов НС, уменьшаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNnRzVvuIe1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtnpf8x0Pybj",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5duc8hg6Ivpv",
        "colab_type": "text"
      },
      "source": [
        "**4.11** меняем число слоев НС, уменьшаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0INWnvjEN0_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmaCX5R6P0ap",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gu3Wa44Ifc7",
        "colab_type": "text"
      },
      "source": [
        "**4.10** меняем число слоев НС, увеличиваем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGHyD8nmIvGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(4500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3500, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJqX0p4LPPi3",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvZdMaxqFHYw",
        "colab_type": "text"
      },
      "source": [
        "#Вывод результатов\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/Hm41rb1zqQo?t=9144"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEvMFXMAD_dQ",
        "colab_type": "text"
      },
      "source": [
        "**Выводим результаты таблицей**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u80qsUuIEmL1",
        "colab_type": "code",
        "outputId": "9a5d1eec-d271-4411-c066-8a2bf8a07684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "#Выводим названия колонок\n",
        "print('{:>10} {:>10} {:>10} {:>10}'.format('predict', 'y', 'error', 'error %'))\n",
        "\n",
        "#Выводим 30 примеров\n",
        "for i in range(30):\n",
        "  price = predict[i] #Запоминаем предсказанную цену\n",
        "  real_price = y_train[n_val+i] #Запоминаем реальзую цену\n",
        "  #Выводим значения колонок\n",
        "  print('{:>10.0f} {:>10.0f} {:>10.0f} {:>10.3f}'.format(price, real_price, abs(price - real_price), ((price / real_price) - 1) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   predict          y      error    error %\n",
            "    120513     165000      44487    -26.962\n",
            "    354320     415000      60680    -14.622\n",
            "    546315     380000     166315     43.767\n",
            "    865303     860000       5303      0.617\n",
            "    224880     220000       4880      2.218\n",
            "    475546     500000      24454     -4.891\n",
            "    528614     650000     121386    -18.675\n",
            "   1911545    1150000     761545     66.221\n",
            "    743456     570000     173456     30.431\n",
            "    522603     520000       2603      0.501\n",
            "    315563     319000       3437     -1.078\n",
            "    733219     760000      26781     -3.524\n",
            "    215535     235000      19465     -8.283\n",
            "    440275     415000      25275      6.090\n",
            "    242138     255000      12862     -5.044\n",
            "    280464     273000       7464      2.734\n",
            "   1545036    1550000       4964     -0.320\n",
            "    967659     821000     146659     17.863\n",
            "     80201      55000      25201     45.821\n",
            "    294184     282000      12184      4.320\n",
            "    105990      90000      15990     17.767\n",
            "    280794     265000      15794      5.960\n",
            "    337226     450000     112774    -25.061\n",
            "    645407     599000      46407      7.747\n",
            "    470338     449000      21338      4.752\n",
            "    665304     570000      95304     16.720\n",
            "    758298     669000      89298     13.348\n",
            "    714352     720000       5648     -0.784\n",
            "    112885     275000     162115    -58.951\n",
            "    139470     162000      22530    -13.907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Feyvyn-cEh6G",
        "colab_type": "text"
      },
      "source": [
        "**Строим 2d карты распределения ошибки от цены**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBjk8OeImqGR",
        "colab_type": "code",
        "outputId": "23362834-7d38-4a62-fc75-7087bad9eff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "#Делаем маску - машины, с ценой до 3.000.000р\n",
        "mask = y_train[n_val:] < 3e+6\n",
        "x = y_train[n_val:] #Вытаскиваем все реальные цены\n",
        "y = abs_delta #Вытаскиваем модули ошибки\n",
        "yp = 100*abs_delta / y_train[n_val:] #Расчитываем процент ошибки\n",
        "\n",
        "#Фильтруем по маске - только машины с ценой до 3млн\n",
        "x = x[mask]\n",
        "y = y[mask]\n",
        "yp = yp[mask]\n",
        "\n",
        "#Выводим 2d карту - ошибка от цены\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel('Цена')\n",
        "plt.ylabel('Ошибка')\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "#Выводим 2d карту - процент ошибки от цены\n",
        "plt.scatter(x, yp)\n",
        "plt.xlabel('Цена')\n",
        "plt.ylabel('Процент ошибки')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk2EYhlE6/j+m/+3CXLsojwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3df3xcdZ3v8dcn6bQkgqRI5NGmLS1a\nywX5UYhQH/UqlV0KKtDFHwvitSLX7lUQcde67YpSXO6l3i66cBVXFK4oLJQf3VBELVyKPx6sLaSm\nUCpUCkLbASFagmIDTZPP/eN8J51M5seZX5lM8n4+HvPIme85M+d7Msn5zPe3uTsiIiKlaqh1BkRE\npL4pkIiISFkUSEREpCwKJCIiUhYFEhERKcuEWmegGg499FCfOXNmrbMhIlJXNm3a9Ad3by32dWMy\nkMycOZPOzs5aZ0NEpK6Y2XOlvE5VWyIiUhYFEhERKYsCiYiIlEWBREREyqJAIiIiZRmTvbZK1dGV\nZNW6bTzf08vUliaWLpzDorlttc6WiMiopkASdHQlWb5mC719/QAke3pZvmYLgIKJiEgeqtoKVq3b\nNhhEUnr7+lm1bluNciQiUh8USILne3qLShcRkYgCSTC1pamodBERiSiQBEsXzqEp0TgkrSnRyNKF\nc2qUIxGR+qDG9iDVoK5eWyIixalaIDGzG4EPAC+5+9tD2irgTGAv8DRwgbv3hH3LgQuBfuASd18X\n0k8HrgEage+5+8pq5XnR3DYFDhGRIlWzauv7wOkZafcDb3f3Y4HfAssBzOwo4Fzg6PCa68ys0cwa\ngW8BZwBHAeeFY0VEZJSoWiBx918AuzPS7nP3feHpBmBa2D4buM3dX3f33wHbgZPCY7u7P+Pue4Hb\nwrEiIjJK1LKx/ZPAT8J2G7Azbd+ukJYrfRgzW2JmnWbW2d3dXYXsiohINjUJJGb2JWAfcEul3tPd\nr3f3dndvb20teoEvEREp0Yj32jKzTxA1wp/q7h6Sk8D0tMOmhTTypIuIyCgwoiWS0APri8BZ7r4n\nbdda4Fwzm2Rms4DZwMPAI8BsM5tlZhOJGuTXjmSeRUQkv2p2/70VOAU41Mx2AZcT9dKaBNxvZgAb\n3P1/uPtWM7sd+A1RlddF7t4f3udiYB1R998b3X1rtfIsIiLFs/21S2NHe3u7d3Z21jobIiJ1xcw2\nuXt7sa/TyPYCtEaJiEh+CiR5aI0SEZHCNGljHlqjRESkMAWSPLRGiYhIYQokeWiNEhGRwhRI8tAa\nJSIihamxPQ+tUSIiUpgCSQFao0REJD9VbYmISFkUSEREpCwKJCIiUhYFEhERKYsCiYiIlEWBRERE\nyqJAIiIiZVEgERGRsiiQiIhIWRRIRESkLAokIiJSFgUSEREpiwKJiIiURYFERETKokAiIiJlqVog\nMbMbzewlM3s8Le0QM7vfzJ4KPyeHdDOza81su5k9ZmYnpL1mcTj+KTNbXK38iohIaapZIvk+cHpG\n2jLgAXefDTwQngOcAcwOjyXAtyEKPMDlwMnAScDlqeBTDR1dSeavXM+sZfcyf+V6OrqS1TqViMiY\nUbVA4u6/AHZnJJ8N3BS2bwIWpaX/wCMbgBYzmwIsBO53993u/jJwP8ODU0V0dCVZvmYLyZ5eHEj2\n9LJ8zRYFExGRAka6jeQwd38hbP8eOCxstwE7047bFdJypQ9jZkvMrNPMOru7u4vO2Kp12+jt6x+S\n1tvXz6p124p+LxGR8aRmje3u7oBX8P2ud/d2d29vbW0t+vXP9/QWlS4iIpGRDiQvhiorws+XQnoS\nmJ523LSQliu94qa2NBWVLiIikZEOJGuBVM+rxcDdaekfD7235gGvhCqwdcBpZjY5NLKfFtIqbunC\nOTQlGoekNSUaWbpwTjVOJyIyZlSz+++twK+AOWa2y8wuBFYCf21mTwF/FZ4D/Bh4BtgOfBf4DIC7\n7wb+GXgkPL4a0ipu0dw2PnhiG41mADSa8cET21g0N2uTjIiIBBOq9cbufl6OXadmOdaBi3K8z43A\njRXMWlYdXUlWP7yTfo+abfrdWf3wTtoPP0TBREQkD41sD1as3UrfwNC2/74BZ8XarTXKkYhIfVAg\nCXp6+4pKFxGRiAKJiIiURYEkaLDi0kVEJKJAEgzkGBqZK11ERCIKJEFbjoGHudJFRCSiQBJoQKKI\nSGmqNo6k3qTGiqxat43ne3qZ2tLE0oVzNIZERKQABZI0i+ZqJLuISLFUtSUiImVRIBERkbIokIiI\nSFkKtpGY2bXZ0t39kspnR0RE6k2cxvb3A38GrgNer252Rp+OrqR6comI5BEnkMwB/g74FPAd4EZ3\nH6hqrkaJjq4ky9dsGVzLPdnTy/I1WwAUTEREgoJtJO6+z92/BbwHaAX+08w+VPWcjQKr1m0bDCIp\nvX39rFq3rUY5EhEZfeK0kWwBUjNOGXAwsBpozPmiMeL5nt6i0kVExqM4VVsfqHouRqmpLU0kswSN\nqZp/S0RkUJzuv/vc/bn0B3BGtTM2Gmj+LRGRwuIEknvN7EgAM5tjZj8Hjq9utkaHRXPbuOqcY2hr\nacKIZgK+6pxj1NAuIpImTtXWecCtZvYzYAFwibv/oqq5GkU0/5aISH5xem09QTSW5L3AVeMpiIiI\nSGEFA0notfVT4I3AzWb2mJk9VvWciYhIXahJry0z+zzw34m6FW8BLgCmALcBbwI2Af/N3fea2STg\nB8CJwB+Bv3X3ZyudJxERKU3OEomZGUDopdUCnBkeLSGtJGbWBlwCtLv724nGo5wLfA34hru/FXgZ\nuDC85ELg5ZD+jXCciIiMEvmqtjYAmNnngFuAN4fHzWZ2cZnnnQA0mdkEoBl4gagN5s6w/yZgUdg+\nOzwn7D81FeRERKT28lVtpUazXwic7O5/ATCzrwG/Ar5ZygndPWlm/wLsAHqB+4iqsnrcfV84bBeQ\n6irVBuwMr91nZq8QVX/9If19zWwJsARgxowZpWRNRERKkK9EssvMjiWqekqfcKqfMpboNbPJRKWM\nWcBU4A3A6aW+X4q7X+/u7e7e3traWu7biYhITPkCwgrgu0AP8LCZrQnpfwP8exnn/Cvgd+7eDRDe\ndz7QYmYTQqlkGpAMxyeB6USBbQLRXF9/LOP8IiJSQTlLJO7+OHAWcDNR24QDrwCfdvcryzjnDmCe\nmTWHto5Tgd8ADwKpWYUXA3eH7bXhOWH/end3RERkVMhbRRVKDd+u5AndfaOZ3Qn8GtgHdAHXA/cC\nt5nZlSHthvCSG4Afmtl2YDdRDy8RERklrNCXezP7M/sb3iGaSt7d/Y3VzFg52tvbvbOzs9bZEBGp\nK2a2yd3bi31dnEkbrwEeB85z9ze6+0GjOYiIiMjIijPX1mVEvawWmtkDZja/+tkSEZF6EWeFxBPC\n5veJuuxeZ2Y73X3cLnglIiL7xRkPcnXG891EYz9EREQKBxJ3XzASGRkNOrqSrFq3jed7epna0sTS\nhXO0FomISAFxqrY+ky3d3a+rfHZqp6MryfI1W+jtiwbxJ3t6Wb5mC4CCiYhIHnF6bU3J8vhiNTNV\nC6vWbRsMIim9ff2sWretRjkSEakPcaq2vpyZZmanVCU3NfR8T29R6SIiEolTtfXuLMljbhxJU6KB\nPX0DWdNFRCS3OL22lmZJG3ONBr37hgeRfOkiIhKJU7V1Zmaamf2yOtmpnVwzxWh6SBGR/ArW25jZ\nIZkPojVKxpTGPIsuzl+5no6uZM79IiLjWZyqrU1Z0sbc9/TzTp7OzRt2ZN2nrsAiIrnFqdqaNRIZ\nqbUrFx0DwK0bd9KfpT4r1RVYgUREZKg4VVsJM7vEzO4Mj4vNLDESmRtpVy46hqeveh+5KrnUFVhE\nZLg4fVu/DZwIXBceJ1Lhxa5Gm6ktTUWli4iMZ3ECyTvcfbG7rw+PC4B3VDtjtbR04RyaEkP7EzQl\nGlm6cE6NciQiMnrFaWzvN7O3uPvTAGZ2BNBf4DV1LdUOogkcRUQKizsg8UEze4Zomd3DgQuqmqtR\nYNHcNgUOEZEY4vTaesDMZgOpep1t7v56dbMlIiL1Ik6JhBA4HqtyXkREpA5pRkIRESmLAomIiJQl\nzoDEH1X6pGbWEgY3PmlmT5jZO8M8Xveb2VPh5+RwrJnZtWa23cweM7MTKp0fEREpXZwSydQqnPca\n4KfufiRwHPAEsAx4wN1nAw+E5wBnALPDYwljfDCkiEi9idPYfoSZrc1MdPezSjmhmR0MvBv4RHif\nvcBeMzsbOCUcdhPwM+AfgbOBH7i7AxtCaWaKu79QyvlFRKSy4gSSbuDqCp5zVnjP/2tmxxHNLvw5\n4LC04PB74LCw3QbsTHv9rpA2JJCY2RKiEgszZswoKWMdXUkNQhQRKVKcQPKqu/+8wuc8Afisu280\ns2vYX40FgLu7mRU1Vb27Xw9cD9De3l70NPcdXUmWr9lCb180aF9Tx4uIxBOnjeSqCp9zF7DL3TeG\n53cSBZYXzWwKQPj5UtifBKanvX5aSKuoVeu2DQaRlNTU8SIiklucEskBZvbxzER3/0EpJ3T335vZ\nTjOb4+7bgFOB34THYmBl+Hl3eMla4GIzuw04GXilGu0juaaI19TxIiL5xQkkqZl+PwLcHrYdKCmQ\nBJ8FbjGzicAzRHN3NQC3m9mFwHPhfAA/Bt4HbAf2UKV5vqa2NJHMEjQ0dbyISH5x5tr6LICZvSu1\nXS533wy0Z9l1apZjHbioEufNZ+nCOUPaSEBTx4uIxBFrrq1gzK3Tnk5Tx4uIlKZgIDGz/0MURKaZ\n2bWpdHe/pJoZqwVNHS8iUrw4JZLO8HNTNTMiIiL1KU4byU1m1gTMCL2sREREBsWp2joT+BdgIjDL\nzI4HvlrqFCmj3WUdW7h140763Wk047yTp3PlomNqnS0RkVErzoDEFcBJQA8M9rg6oop5qpnLOrZw\n84Yd9HvUr6DfnZs37OC/fPkndHRVfAykiMiYECeQ9Ln7KxlpA9XITK3dsmFH1vTevgGWr9miYCIi\nkkWcQLLVzD4KNJrZ7NCL6z+rnK+ayNe/WdOliIhkFyeQfBY4GngduBX4E3BpNTM1Wmm6FBGR4eL0\n2toDfCk8ADCzN5vZm4GX3f3PVczfqKLpUkREhovTa2vYhI3APxFVb90F3FvpTNXK/LccwkNP7866\nT9OliIhkV8ykjekOdPdPVjoztdTRleTXOzL7FETaNF2KiEhOsSdtTBfGkowp2dYjAWg0UxAREcmj\nmEkb0425CRxzNaT3uw+ulAia1FFEJFMxkzYOJjEGByTmWo8Eoq6/V9yzldf6BrQUr4hIhjjdfzuJ\nJmxMPTpJ68E1VixdOIdEo+Xc//KePi3FKyKSRdxJGycCbwtJ29y9r7rZqpESKuw0tkRExrs4VVun\nADcBzxJVa003s8Xu/ovqZm1krVq3jb6B4iOJxpaIyHgXp7H9auC01BTyZvY2ohHuJ1YzYyMtTsnC\nGFpo0dgSEZF4bSSJ9HVI3P23QKJ6WaqNOCULJxpTYuHnVecco4Z2ERn3Yq2QaGbfA24Oz89n/6qJ\nY8bShXNYvmZL1rEkKW0tTTy07L0jmCsRkdEvTiD5NHARkFqj/ZfAdVXLUY2kShZf+o8t/GXv8GDS\nAKrGEhHJomDVlru/DnwTuAK4HPhWSCuLmTWaWZeZ/Sg8n2VmG81su5mtDj3FMLNJ4fn2sH9muefO\nZdHcNhKN2X8lByQaVI0lIpJFwUBiZu8HngauIQoo283sjAqc+3PAE2nPvwZ8w93fCrwMXBjSLySa\nZfitwDfCcVXT05u9Z/OevjG5lpeISNniNLZfDSxw91Pc/T3AAqIbesnMbBrwfuB74bkB7wXuDIfc\nBCwK22eH54T9p4bjRURkFIgTSP7s7tvTnj8DlLsGyb8CX2T/kr1vAnrcfV94vgtI1SO1ATsBwv5X\nwvFDmNkSM+s0s87u7u4ys5edltoVERku1hQpZvZjM/uEmS0G7gEeMbNzzOycYk9oZh8AXnL3TcW+\nNh93v97d2929vbW1teT3yVfU0XQoIiLDxQkkBwAvAu8BTgG6gSbgTOADJZxzPnCWmT0L3EZUpXUN\n0GJmqV5k04DU1/8kMB0g7D8Y+GMJ543l/Hkzcu7TdCgiIsPFmWvrgkqe0N2XA8thcPqVL7j7+WZ2\nB/AhouCyGLg7vGRteP6rsH+9u1dlGvuOriQPPpm7WuzgpjE3DlNEpGw5A4mZXZvvhe5+Sb79JfhH\n4DYzuxLoAm4I6TcAPzSz7cBu4NwKnxeIgkihAYk9vX0c/ZWfsmdvv9YjEREJ8pVIzga+Us2Tu/vP\ngJ+F7WeAk7Ic8xrw4WrmA3KvkJgpNVgx2dPL0jsfBbQeiYiMb/kCyW53vynP/jGllPaPvn7ninu2\nKpCIyLiWr7F9zC2nm0+p08G/vGdsLs0iIhJXnF5b48KCI0vvMiwiMp7lq9o6zsz+lCXdAHf3N1Yp\nTzWRr7dWPi3qySUi41zOQOLujSOZkVpLltBGkmgwVpx1NB1dSVat28bzPb3qzSUi406caeTHhUYz\n+osYntLSlGDFWUcDDOk2nOzpZfmaLYB6c4nI+KA2kqCYIALwhkkTWDS3LWu34d6+/iHTqXR0JZm/\ncj2zlt3L/JXrNWeXiIwpKpEExZZIUt2Fc3UbTqVnDnRUiUVExhqVSIJiSySp7sK5ug2n0uOUWERE\n6pkCSdBWxDiSBtu/7O7ShXNoSgztl9CUaBzcX6jEIiJS7xRIgmLWYx9wuKNzB/NXrufzqzczaUID\nk5sTGFFAuuqcYwarrQqVWERE6p3aSEr00NO7B7d7evtoSjTyjb89fli7x9KFc4ZNBpleYhERqXdW\npRnZa6q9vd07OzuLes38letLGkuSrtGMAfdhY0k0zkRE6oGZbXL39mJfpxJJUIk2i1SDfWbPrNRD\nRGQsUhtJUOk2C/XMEpHxQoEkKLbNIt/a7inlVpWJiNQDBZJg0dw2PpZnvfZMTuEJGw00il1ExjwF\nkjTthx8S+9i2libeMCl/E5ODqrdEZMxTY3vQ0ZUcXDo3jrjVVhp4KCJjnUokwRX3bKWvv/JdoTXw\nUETGOgWSoBpL5mrgoYiMB6raqhADWpoTuMMrvX0aeCgi44YCSdDSlKCnt7RSSVtLEw8te2+FcyQi\nUh9GvGrLzKab2YNm9hsz22pmnwvph5jZ/Wb2VPg5OaSbmV1rZtvN7DEzO6Ea+UqtdliKBUe2auEq\nERm3atFGsg/4B3c/CpgHXGRmRwHLgAfcfTbwQHgOcAYwOzyWAN+uRqbKqYK6a1OSZE8vzv7pUSoR\nTLSyoojUgxEPJO7+grv/Omz/GXgCaAPOBm4Kh90ELArbZwM/8MgGoMXMpoxwtvPKtnDVP9z+aFkB\nILWyYjUClIhIJdW015aZzQTmAhuBw9z9hbDr98BhYbsN2Jn2sl0hLfO9lphZp5l1dnd3Vy3PcfW7\nlxUAtLKiiNSLmgUSMzsQuAu41N3/lL7Po7ntixrU4e7Xu3u7u7e3trZWMKf5TW7OP00KlBYAtLKi\niNSLmgQSM0sQBZFb3H1NSH4xVWUVfr4U0pPA9LSXTwtpo0Lc8SfFBgCtrCgi9aIWvbYMuAF4wt2/\nnrZrLbA4bC8G7k5L/3jovTUPeCWtCqxuHNyUKKrxvNBa8OVQI76IVNKIr5BoZu8CfglsAQZC8j8R\ntZPcDswAngM+4u67Q+D5JnA6sAe4wN3zLn9YygqJADOX3Vv0a+IyYEKjDZmGpSnRyAdPbOPBJ7uz\nrp5YqZUV09+npTnBq6/to29gaD7S15kXkfGp1BUStdRummoGklyMoY1BcW/qcYNMqvdXZsN9Jg2q\nFJFSA4nm2gpqVb2TGcbjNMwX0zU4W++vbNSILyKl0hQpwWjqVpvtpp5eAmkwG1wfPiUVgDJLJXED\nhBrxRaRUKpEEo+kbucOQRvDMEkhmEEnJdg1xAoRmKRaRcqhEEkxtaar6GusNAAYDMZqlUtVVEL96\nKlvQWLpwDkvveHRI43q6trT2lUo17ovI+KISSTAS38gbGy1WEElJVVfFKS3lKlUsmtvGgQdk/76Q\namBPBRFNySIipVCJZASVsgJjsqeXxixtIgCNZgy4Fyw99OQYNJkeoPJNyVKpHmQiMjYpkASjqbE9\nU7YgUszYj5bmRNYR+C1p07uUOiVLZvfi9Co5BROR8UFVW0G120cKaWwwEg2W/xgzjKhKKm4Q6ehK\n8upr+7Lue/W1fYNVV6VOyaLJJUVEgWSUOGjSBFZ9+Dja8ty4B9z53cr3Dw4cPP6K+5i57F5mLruX\nuV+9L+c4klwN7X0DPnjDL3VKFk0uKSKq2holenr7WLF2a97lfg9uiqqiOrqSw3pivbynj6V3PgoM\nrVIqdENP7U+9pti2jly93XKVZNSeIjL2KJAEuRq0R1KhNeP/sjeqilqxdmvWUkZfv3Pp6s2sWrdt\n8AZdqFtz+g1/0dy2om/qSxfOGTYFS66SjNpTRMYmVW0F5508vfBBNZYKFIUCTnrX3WxVVimZN/xS\nZgVeNLeNq845hraWpoLtN+O5PUUzLstYpkkb09Ri0sZqSo0TSVUnpXclbssy03C2kkUlZgVOP382\nBvxu5fvLOkeuc1ZzVuVi8lLu71ZVgjISNPtvGgWS/SY3J+jZ05f15lNo/i4oblbgbDc7oODswy1N\nCVacdXTFbpS5btwfPLGNHz36wrASXakBM+7Nff7K9VmDaNzfbTWDvEg6BZI0CiS5GXD+vBm0H35I\nrOnl45YWct3sJk1oKFgV12BR9+f0AZup6fVzlaDyyXXjzpyyP12x0+gXc3OftezerOeN+7utRCBS\naUbiKDWQqLF9nHHg5g07uHnDjtjHz1+5vuDNJ1f7R5w5wgYcBjJG/aeepUpJxTTM5+qplu8rU7Hd\nlYuZCaDYnm1x8xYnz+rgkF+lg+x4DdoKJFJQsqeXS1dv5o7OHdzyqXcOpqf/04xEuTbulC2lTMCZ\nPso/lzjXm+28C45szRq4FxzZGutcuaod4wSicqa+GesqHWTHc9BWIEnTNgIzANezh57ezZzLfsLX\nPngsnc/t5pYNO0YkgKTL/Bae7Rtgti7JhaRG+ef6h+/oSrL0zkcLzpdm4dj093nwye6sx6anp1/H\nwU0J/rJ33+C5ck2RE2ei0bE2YLSS3/grHWTHc9BWIEmT65uj7Pf6vgEuXb25ZudvntjI/JXrs95w\nUyWnpkQDDbZ/upmmRAO9fQN53zc1yj/1D39ZxxZu3biTfncazZjQaLEm3XTginu2DrnZ5fpykrqZ\nZ36TzdWmlD5J54IjW1m1bhufX715yA0180aba561bKWZXDfpbL3+Smm7KldmME/29GYdhBtXoc+l\nWNUK2vVQXabG9jTHX3FfwYZhGdsazTiitZmnXvpL1c81uTlB11dOy9mYnk2ugbMNBpMmDA+YDUC2\nENqUaOCqc44t2P37hBkH89DTu/PnqcG4+sPHxZ77LX0Gh+ZEA5MSjTl7Fqab+9X7sgbFyc0JLj9z\naK+/BUe28uCT3Tlvvpd1bMn5pbHUTgx79u7Lmr9yej4uOLKVuzYlR6zHnhrbK0BBRPrdRySIALwW\nbg7FfGPNNfvCgJO11JWrHNbbN8DSOx4dfP73t28etlZOb19/wSAC0D/gfD6UUjNvbuk3xpbmBK/s\n6RuSpz19A+wJ+S7UppDtJp1K//zqzYPVrMme3iFBIvW+nc/t5sEnuwsG7WxtV9lu8Ksf2TmkdNRg\nkGgc3vtwwZGtsUoVmVMfZV5HymisLlOJJM146P4rks4Ai7lqZ1yTmxMcNeWgWEEom2zf4Du6kmVX\nqebr/p1ucnOC5okTBm/6zRMbYn+5mBgCSSm/zlylx1yqUa2oEomIFM2BSn+XfHlPX8lBBKJv4jOX\n3cvk5gTulaspiHuZL+/pGyz9FNv5Zm8Ji9elFBNEYGgbUedzu7ll447Bz7I50cD/Squ6rLa6CSRm\ndjpwDdAIfM/dV9Y4SyJSRbmqsmS/1Px7mfb0DfD3t2evbqyGupi00cwagW8BZwBHAeeZ2VG1zZWI\nyOg14CO38mtdBBLgJGC7uz/j7nuB24Cza5wnEZFRbaTGC9VLIGkDdqY93xXSBpnZEjPrNLPO7u7s\nA8BERCqlwRiyfMJoFHcannLVTRtJIe5+PXA9RL22SnmPyTkGb4mIZProyTO4ctExg89zjXMpRtye\nZXE0GLFmP6jIuUbkLOVLAukrT00LaRV1+ZlH09hghQ8UGSfeOCn7omgpDQYfmzeDj82bQaPl/985\n7KCJlcxaSZoS0S2vQFZpa2mKrinL/cDCNacHESj//tHYYJw/b0bOhehSJjYOP0fmeZsTDXz9I8er\n11aGR4DZZjaLKICcC3y00idJ/dKvuGerSiZStEaDMnp/VlxzogFn/0DF1PiODc+8PGRgo9nwLsAN\nNvwbd6FBdZk31mwu69jCv2/cMThuJTXCHob+36Xy1BYG/63ZtGtw4KIZvLX1DTzTvYd+dwyYOKGB\n1/cNDF73xAmN9PT2FZzKpdA1tR9+SOzpSbLdP1Jr7XQ+t3vIlDvnnTw953un0lODHFO/q9R7ZZsK\np9bTptTNgEQzex/wr0Tdf2909/+Z69hSBySKiIxnY35Aorv/GPhxrfMhIiJD1UsbiYiIjFIKJCIi\nUhYFEhERKYsCiYiIlKVuem0Vw8y6gedKeOmhwB8qnJ1a0bWMTrqW0UnXEjnc3YcvyFLAmAwkpTKz\nzlK6vo1GupbRSdcyOulayqOqLRERKYsCiYiIlEWBZKjra52BCtK1jE66ltFJ11IGtZGIiEhZVCIR\nEZGyKJCIiEhZFEgCMzvdzLaZ2XYzW1bjvDxrZlvMbLOZdYa0Q8zsfjN7KvycHNLNzK4N+X7MzE5I\ne5/F4finzGxxWvqJ4f23h9davnMUmfcbzewlM3s8La1mec93jhKvZYWZJcNnsznMSp3atzycZ5uZ\nLUxLz/q3ZWazzGxjSF9tZhND+qTwfHvYP7PQOWJcy3Qze9DMfmNmW83sc6X+3mr92eS5lrr7bMzs\nADN72MweDddyRaXPX8lrzMndx/2DaGr6p4EjgInAo8BRNczPs8ChGWn/G1gWtpcBXwvb7wN+QrS4\n2jxgY0g/BHgm/JwctieHfcI/YIIAAATzSURBVA+HYy289ox85ygy7+8GTgAeHw15z3WOMq5lBfCF\nLMceFf5uJgGzwt9TY76/LeB24Nyw/W/Ap8P2Z4B/C9vnAqvznSPmtUwBTgjbBwG/De9Xd59Nnmup\nu88mXPuBYTsBbAy/i4qcv5LXmPc6yr3pjYUH8E5gXdrz5cDyGubnWYYHkm3AlLA9BdgWtr8DnJd5\nHHAe8J209O+EtCnAk2npg8flOkcJ+Z/J0JtvzfKe6xxlXMsKst+shvzNAOvC31XWvy2iG8gfgAmZ\nf4Op14btCeE4y3WOEj+ju4G/rufPJsu11PVnAzQDvwZOrtT5K3mN+fKuqq1IG7Az7fmukFYrDtxn\nZpvMbElIO8zdXwjbvwcOC9u58p4vfVeW9HznKFct816Nz/biUBVzo+2v/iv2Wt4E9Lj7viz5GnxN\n2P9KOL4i1xKqKuYSffut688m41qgDj8bM2s0s83AS8D9RCWISp2/kteYkwLJ6PQudz8BOAO4yMze\nnb7To68KVe23Xa1z1HPeg28DbwGOB14Arq7SearCzA4E7gIudfc/pe+rt88my7XU5Wfj7v3ufjww\nDTgJOLLGWSqaAkkkCUxPez4tpNWEuyfDz5eA/yD643rRzKYAhJ8vhcNz5T1f+rQs6eQ5R7lqmfeK\nfrbu/mL4xx8Avkv02ZRyLX8EWsxsQkb6kPcK+w8Ox5d1LWaWILrx3uLua0JyXX422a6lnj+bkP8e\n4EGiaqZKnb+S15iTAknkEWB26MUwkaiBaW0tMmJmbzCzg1LbwGnA4yE/qR4yi4nqhQnpHw89YOYB\nr4RqhHXAaWY2ORTxTyOqA30B+JOZzTMzAz6e8V7ZzlGuWuY91zlKkrohBn9D9NmkznNu6PEyC5hN\n1Pic9W8rfDN/EPhQjjynruVDwPpwfK5zxMm3ATcAT7j719N21d1nk+ta6vGzMbNWM2sJ201EbT1P\nVPD8lbzG3Ipt2BqrD6IeJL8lqp/8Ug3zcQRRz4pHga2pvBDVUT4APAX8P+CQkG7At0K+twDtae/1\nSWB7eFyQlt5O9E/2NPBN9s9wkPUcReb/VqJqhT6ietcLa5n3fOco8Vp+GN7nsfAPNyXt+C+F82wj\n9FjK97cVPuuHwzXeAUwK6QeE59vD/iMKnSPGtbyLqErpMWBzeLyvHj+bPNdSd58NcCzQFfL8OPCV\nSp+/kteY66EpUkREpCyq2hIRkbIokIiISFkUSEREpCwKJCIiUhYFEhERKYsCiUiZzOzVjOefMLNv\n1io/IiNNgURERMqiQCJSRWFCvlVm9kiYTPDvQvopZvajtOO+YGYrwvanwvGPmtldZtZco+yLxKJA\nIlJdFxJN/fEO4B3Ap8IUFvmscfd3uPtxRNNlXFjtTIqUY0LhQ0SkDKcBx5pZak6jg4nmQdoL/Ncw\nfThAK9FEgwBvN7MrgRbgQKL5rURGLQUSkeoy4LPuPiQYmNkpwC/d/QPh+ReIggbA94FF7v6omX0C\nOGWkMitSClVtiVTXOuDTYdpzzOxtYVbnfA4CXgivOb/aGRQpl0okIuVrNrP01QGbgYlm9nPge0TL\n9f46TH/eDSwq8H5fJlrxrzv8PKjiORapIM3+K1IFZnYx8Kq7f7/WeRGpNpVIRKrjGeC1WmdCZCSo\nRCIiImVRY7uIiJRFgURERMqiQCIiImVRIBERkbIokIiISFn+P6zM2Q1Ffk4JAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}