{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Февральский курс. Pro. Занятие 2. Предсказание цен машин с Юлы",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/errec-sun/brain/blob/master/DZ%203%20Errec_%D0%A4%D0%B5%D0%B2%D1%80%D0%B0%D0%BB%D1%8C%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D1%83%D1%80%D1%81_Pro_%D0%97%D0%B0%D0%BD%D1%8F%D1%82%D0%B8%D0%B5_2_%D0%9F%D1%80%D0%B5%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%B0%D0%BD%D0%B8%D0%B5_%D1%86%D0%B5%D0%BD_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD_%D1%81_%D0%AE%D0%BB%D1%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvQeueuAX4Jd",
        "colab_type": "code",
        "outputId": "68887dc2-a4c8-4dc3-8250-282f3246da15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "from google.colab import files\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adadelta, Adam\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O10ZA-msmjvL",
        "colab_type": "text"
      },
      "source": [
        "#Загрузка данных\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/Hm41rb1zqQo?t=7582"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVAD74YJKPSc",
        "colab_type": "code",
        "outputId": "827969cb-3262-4ad0-c6ff-52d368cf8b2b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "#Загружаем файлы\n",
        "files.upload()\n",
        "!ls #Выводим содержимое корневой папки"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d42b15b6-2ee8-47f7-adc4-721ef45bdd96\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d42b15b6-2ee8-47f7-adc4-721ef45bdd96\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cars_new for Python.csv to cars_new for Python.csv\n",
            "'cars_new for Python.csv'   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX0gMyfrm67-",
        "colab_type": "code",
        "outputId": "80d78d20-d36a-4ab7-bcd1-b9230994e8cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "#Считываем csv с помощью pandas\n",
        "cars = pd.read_csv('cars_new for Python.csv', sep=',')\n",
        "cars[:5] #Выводим первые 5 машин "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mark</th>\n",
              "      <th>model</th>\n",
              "      <th>price</th>\n",
              "      <th>year</th>\n",
              "      <th>mileage</th>\n",
              "      <th>body</th>\n",
              "      <th>kpp</th>\n",
              "      <th>fuel</th>\n",
              "      <th>volume</th>\n",
              "      <th>power</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kia</td>\n",
              "      <td>cerato</td>\n",
              "      <td>996000</td>\n",
              "      <td>2018</td>\n",
              "      <td>28000</td>\n",
              "      <td>седан</td>\n",
              "      <td>автомат</td>\n",
              "      <td>бензин</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>daewoo</td>\n",
              "      <td>nexia 1 поколение [2-й рестайлинг]</td>\n",
              "      <td>140200</td>\n",
              "      <td>2012</td>\n",
              "      <td>60500</td>\n",
              "      <td>седан</td>\n",
              "      <td>механика</td>\n",
              "      <td>бензин</td>\n",
              "      <td>1.5</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>suzuki</td>\n",
              "      <td>jimny 3 поколение [рестайлинг]</td>\n",
              "      <td>750000</td>\n",
              "      <td>2011</td>\n",
              "      <td>29000</td>\n",
              "      <td>внедорожник</td>\n",
              "      <td>автомат</td>\n",
              "      <td>бензин</td>\n",
              "      <td>1.3</td>\n",
              "      <td>85.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bmw</td>\n",
              "      <td>x1 18 e84 [рестайлинг]</td>\n",
              "      <td>970000</td>\n",
              "      <td>2014</td>\n",
              "      <td>49500</td>\n",
              "      <td>кроссовер</td>\n",
              "      <td>автомат</td>\n",
              "      <td>бензин</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chevrolet</td>\n",
              "      <td>lacetti 1 поколение</td>\n",
              "      <td>205000</td>\n",
              "      <td>2007</td>\n",
              "      <td>151445</td>\n",
              "      <td>седан</td>\n",
              "      <td>механика</td>\n",
              "      <td>бензин</td>\n",
              "      <td>1.4</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        mark                               model   price  ...    fuel  volume  power\n",
              "0        kia                              cerato  996000  ...  бензин     2.0  150.0\n",
              "1     daewoo  nexia 1 поколение [2-й рестайлинг]  140200  ...  бензин     1.5   80.0\n",
              "2     suzuki      jimny 3 поколение [рестайлинг]  750000  ...  бензин     1.3   85.0\n",
              "3        bmw              x1 18 e84 [рестайлинг]  970000  ...  бензин     2.0  150.0\n",
              "4  chevrolet                 lacetti 1 поколение  205000  ...  бензин     1.4   95.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxh46Ndz4xNZ",
        "colab_type": "code",
        "outputId": "60cae212-9cd9-4fdb-abe6-426beae46c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(cars.values.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70119, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXlgXPAem_mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём словарь поле - его индекс\n",
        "def create_dict(s):\n",
        "  ret = {} #Создаём пустой словарь\n",
        "  for _id, name in enumerate(s): #Проходим по всем парам - id и название\n",
        "    ret.update({name: _id}) #Добавляем в словарь\n",
        "  return ret\n",
        "\n",
        "#ФУнкция преобразования в one hot encoding\n",
        "def to_ohe(value, d):\n",
        "  arr = [0] * len(d)\n",
        "  arr[d[value]] = 1\n",
        "  return arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhaCKb-3nCIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём словари по всем текстовым колонкам\n",
        "marks_dict = create_dict(set(cars['mark']))\n",
        "models_dict = create_dict(set(cars['model']))\n",
        "bodies_dict = create_dict(set(cars['body']))\n",
        "kpps_dict = create_dict(set(cars['kpp']))\n",
        "fuels_dict = create_dict(set(cars['fuel']))\n",
        "\n",
        "#Запоминаем цены\n",
        "prices = np.array(cars['price'], dtype=np.float)\n",
        "\n",
        "#Запоминаем числовые параметры\n",
        "#И нормируем\n",
        "years = preprocessing.scale(cars['year'])\n",
        "mileages = preprocessing.scale(cars['mileage'])\n",
        "volumes = preprocessing.scale(cars['volume'])\n",
        "powers = preprocessing.scale(cars['power'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MdND_2CBXmH",
        "colab_type": "code",
        "outputId": "3ff60554-7bf9-4126-d8b4-fc37eed8f1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(marks_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'daewoo': 0, 'opel': 1, 'kia': 2, 'nissan': 3, 'toyota': 4, 'mercedes-benz': 5, 'honda': 6, 'ford': 7, 'volkswagen': 8, 'suzuki': 9, 'chevrolet': 10, 'bmw': 11, 'peugeot': 12, 'hyundai': 13, 'chery': 14, 'renault': 15, 'subaru': 16, 'mazda': 17, 'audi': 18, 'mitsubishi': 19, 'skoda': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXEs8aZiMdBM",
        "colab_type": "text"
      },
      "source": [
        "0 Создаем полную базу данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFQNnvd7nJBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNsvGyHXl8sr",
        "colab_type": "code",
        "outputId": "12ade04b-7a28-4382-dede-3a057dfb7a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "#Выводим один x_train\n",
        "print(x_train[0,:20])\n",
        "print(x_train[0,-20:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 1.          0.          0.          0.          0.          0.\n",
            "  0.          1.          0.          0.          0.          0.\n",
            "  0.          1.          0.          0.          1.5200145  -1.40018212\n",
            "  0.12288486  0.22905575]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZCBfyifHRhZ",
        "colab_type": "text"
      },
      "source": [
        "#Нейронка\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/Hm41rb1zqQo?t=8166"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsiHCClRSUI3",
        "colab_type": "code",
        "outputId": "832975ca-29ee-4216-ed72-9a7f49a62422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Создаём сеть\n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 310s 5ms/sample - loss: 0.5098 - val_loss: 0.4798\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 308s 5ms/sample - loss: 0.3127 - val_loss: 0.3895\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 309s 5ms/sample - loss: 0.2583 - val_loss: 0.3462\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 307s 5ms/sample - loss: 0.2306 - val_loss: 0.3238\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 309s 5ms/sample - loss: 0.2120 - val_loss: 0.3011\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 305s 5ms/sample - loss: 0.1980 - val_loss: 0.2874\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 307s 5ms/sample - loss: 0.1869 - val_loss: 0.2748\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 306s 5ms/sample - loss: 0.1780 - val_loss: 0.2650\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 308s 5ms/sample - loss: 0.1707 - val_loss: 0.2565\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1639 - val_loss: 0.2489\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1582 - val_loss: 0.2435\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1536 - val_loss: 0.2374\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1493 - val_loss: 0.2321\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1452 - val_loss: 0.2278\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 306s 5ms/sample - loss: 0.1417 - val_loss: 0.2228\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 306s 5ms/sample - loss: 0.1384 - val_loss: 0.2189\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 303s 5ms/sample - loss: 0.1353 - val_loss: 0.2147\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 300s 5ms/sample - loss: 0.1326 - val_loss: 0.2122\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 301s 5ms/sample - loss: 0.1297 - val_loss: 0.2080\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 302s 5ms/sample - loss: 0.1276 - val_loss: 0.2054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Средняя ошибка:  75725.0\n",
            "Средняя цена:  530277.0\n",
            "Процент ошибки: 14.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWtHB2eBIUMa",
        "colab_type": "text"
      },
      "source": [
        "1.1 создаем базу данных\n",
        ", **марки и модели** машин не включаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hRN7v2iH6rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr =  to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvbw0LNrJLTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AioooPUoJm87",
        "colab_type": "code",
        "outputId": "44a36659-28db-4d33-f3a8-8affb0c720f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Создаём сеть\n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.4923 - val_loss: 0.4638\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.3062 - val_loss: 0.3909\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.2678 - val_loss: 0.3604\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.2471 - val_loss: 0.3412\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.2331 - val_loss: 0.3250\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.2232 - val_loss: 0.3149\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.2153 - val_loss: 0.3051\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.2084 - val_loss: 0.2989\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.2034 - val_loss: 0.2910\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1983 - val_loss: 0.2847\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.1948 - val_loss: 0.2819\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1914 - val_loss: 0.2769\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1884 - val_loss: 0.2731\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.1855 - val_loss: 0.2685\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1831 - val_loss: 0.2656\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1807 - val_loss: 0.2618\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.1784 - val_loss: 0.2601\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.1764 - val_loss: 0.2575\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1745 - val_loss: 0.2546\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1729 - val_loss: 0.2519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Средняя ошибка:  107160.0\n",
            "Средняя цена:  530277.0\n",
            "Процент ошибки: 20.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCHQ_1ugNctW",
        "colab_type": "text"
      },
      "source": [
        "**1.2** создаем базу данных без учета **модели** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ3t1fH1N7zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okVrzhGQOoxI",
        "colab_type": "code",
        "outputId": "07ec0fd3-50ad-4662-9ca7-384d7f005ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "#Создаём сеть без \"модели\"\n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.4719 - val_loss: 0.4540\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.2935 - val_loss: 0.3758\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.2489 - val_loss: 0.3396\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.2253 - val_loss: 0.3161\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.2096 - val_loss: 0.2997\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1979 - val_loss: 0.2862\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 174s 3ms/sample - loss: 0.1889 - val_loss: 0.2768\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 174s 3ms/sample - loss: 0.1816 - val_loss: 0.2675\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 174s 3ms/sample - loss: 0.1758 - val_loss: 0.2606\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1707 - val_loss: 0.2550\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1659 - val_loss: 0.2494\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1620 - val_loss: 0.2432\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1585 - val_loss: 0.2397\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1554 - val_loss: 0.2354\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 176s 3ms/sample - loss: 0.1525 - val_loss: 0.2313\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.1498 - val_loss: 0.2280\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1471 - val_loss: 0.2261\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1450 - val_loss: 0.2225\n",
            "Epoch 19/20\n",
            "28580/60000 [=============>................] - ETA: 1:29 - loss: 0.1804"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQyq08osRUCZ",
        "colab_type": "text"
      },
      "source": [
        "**1.3** Создаем базу без учета типа **кузова** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0g-uqz7RVKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OOlWf4zRteh",
        "colab_type": "code",
        "outputId": "78cae870-0c93-4138-a6fb-68430147d16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "#Создаём сеть без \"кузова\"\n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 308s 5ms/sample - loss: 0.5149 - val_loss: 0.4799\n",
            "Epoch 2/30\n",
            " 1220/60000 [..............................] - ETA: 4:46 - loss: 0.2559"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e9d66733b9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP9GS5uSSIeV",
        "colab_type": "text"
      },
      "source": [
        "**1.4** Создаем базу без учета типа **КПП** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4E_MPKHSJM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzeNUP-1SJ8V",
        "colab_type": "code",
        "outputId": "f09d1c03-2106-47ad-aa71-66ee2c1d9ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 6800/60000 [==>...........................] - ETA: 4:28 - loss: 0.7763"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzEEhwSgSenm",
        "colab_type": "text"
      },
      "source": [
        "**1.5** Создаем базу без учета типа **топлива** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe7lkujtSyf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78lkq8kESyH4",
        "colab_type": "code",
        "outputId": "c7679292-cbfc-40d9-8329-caa5fe98aa7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 4700/60000 [=>............................] - ETA: 4:42 - loss: 0.8714"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcm-wGZUSziV",
        "colab_type": "text"
      },
      "source": [
        "**1.6** Создаем базу без учета типа **обем двигателя** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIVjL336TI0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7UUsjIsTIfz",
        "colab_type": "code",
        "outputId": "b7a16b50-e1d8-42b9-fdc9-ab1e1aa77bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 5300/60000 [=>............................] - ETA: 4:43 - loss: 0.8028"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo72bKhCTJqB",
        "colab_type": "text"
      },
      "source": [
        "**1.7** Создаем базу без учета типа **мощности двигателя** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOPZGR5MUfta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] \n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Md1Ydm1UfGN",
        "colab_type": "code",
        "outputId": "685fa188-a13e-4714-a4ac-354ba8d4f1d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни проценt ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 6220/60000 [==>...........................] - ETA: 4:34 - loss: 1.0294"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7tMcrVVbxR",
        "colab_type": "text"
      },
      "source": [
        "**1.8** Создаем базу без учета **года выпуска** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nA44oBBVnaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESHcBodEVn79",
        "colab_type": "code",
        "outputId": "73a18e5e-8ec8-4685-cc16-32d9d9a047b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 6920/60000 [==>...........................] - ETA: 4:32 - loss: 1.0975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd0gGLSJUhCq",
        "colab_type": "text"
      },
      "source": [
        "**1.9** Создаем базу без учета **пробега**  автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbCwhaI3UwFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OshvRh2YUwlb",
        "colab_type": "code",
        "outputId": "cb25354f-9290-4d91-c882-1bd155025d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            " 2060/60000 [>.............................] - ETA: 5:13 - loss: 0.7004"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ithJPd9vVrbL",
        "colab_type": "text"
      },
      "source": [
        "**1.10** Создаем базу без учета **марки** автомобиля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W04W30gLz5qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# создаем базу данных\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_4FIGczby-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le_l86n_7o-R",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJih6MBYcch6",
        "colab_type": "text"
      },
      "source": [
        "**2** Отключаем нормализацию входных данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C5VMDR34bnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Задаем числовые параметры без нормализации\n",
        "\n",
        "years = cars['year']\n",
        "mileages = cars['mileage']\n",
        "volumes = cars['volume']\n",
        "powers = cars['power']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAJHKmkn5kv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# создаем базу данных\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVJmYTz-5izu",
        "colab_type": "code",
        "outputId": "36b65c70-c52e-41e8-ac12-fff91fd7e00b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/20\n",
            "23280/60000 [==========>...................] - ETA: 3:06 - loss: 313.5793"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-067d0e073ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JacvA2Ps7cLu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YIiui66-JDY",
        "colab_type": "text"
      },
      "source": [
        "**3** Проверяем влияние на ошибку, операции преобразования входных данных \"года выпуска автомобиля\" в формат +ohe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlS2yP9n7dZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Запоминаем числовые параметры\n",
        "#И нормируем\n",
        "years = preprocessing.scale(cars['year'])\n",
        "mileages = preprocessing.scale(cars['mileage'])\n",
        "volumes = preprocessing.scale(cars['volume'])\n",
        "powers = preprocessing.scale(cars['power'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNKJCyZP5iBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr = to_ohe(car[0], marks_dict) + \\\n",
        "        to_ohe(car[1], models_dict) + \\\n",
        "        to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        to_ohe(car[3], years(_id)) + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5zoT1m6ERBQ",
        "colab_type": "code",
        "outputId": "f4c1bc9c-bfc3-4dce-b684-e65dd9febbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10119 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 312s 5ms/sample - loss: 0.5507 - val_loss: 0.5121\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 312s 5ms/sample - loss: 0.3287 - val_loss: 0.4059\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 311s 5ms/sample - loss: 0.2691 - val_loss: 0.3593\n",
            "Epoch 4/30\n",
            "35800/60000 [================>.............] - ETA: 2:00 - loss: 0.2505"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e9d66733b9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#Отображаем графики ошибки обучения на всех эпохах\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "airKXGWsBoKL",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAOvZP2QByq8",
        "colab_type": "text"
      },
      "source": [
        "**4**`**Архитектура сети НС**`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwM76wfEC0HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "#Проходам по всем машинам\n",
        "for _id, car in enumerate(np.array(cars)):\n",
        "  #В y_train добавляем цену\n",
        "  y_train.append(prices[_id])\n",
        "  \n",
        "  #В x_train объединяем все параметры\n",
        "  #Категорийные параметры добавляем в ваде ohe\n",
        "  #Числовые параметры добавляем напрямую\n",
        "  x_tr =  to_ohe(car[5], bodies_dict) + \\\n",
        "        to_ohe(car[6], kpps_dict) + \\\n",
        "        to_ohe(car[7], fuels_dict) + \\\n",
        "        [years[_id]] + \\\n",
        "        [mileages[_id]] + \\\n",
        "        [volumes[_id]] + \\\n",
        "        [powers[_id]]\n",
        "  \n",
        "  #Добавляем текущую строку в общий z_train\n",
        "  x_train.append(x_tr)\n",
        "\n",
        "#Превращаем лист в numpy.array\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "#Нормализуем y_train\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1,1)).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLlRChqDCIy4",
        "colab_type": "text"
      },
      "source": [
        "**4.1** добавляем  слой Dropout в НС."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7pQU_wRDei4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "539ZUZvVPanX",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3t3RgjEiGX",
        "colab_type": "text"
      },
      "source": [
        "**4.2** добавляем слой Batch Normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sGuAEBZEiaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLRxXecIPfMU",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHqiPqVtExUL",
        "colab_type": "text"
      },
      "source": [
        "**4.3** меняем активационную функцию elu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd17e_RvFEfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='elu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='elu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzG2SdanPh06",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuDh8OdDFGEI",
        "colab_type": "text"
      },
      "source": [
        "**4.4** меняем активационную функцию linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aucr8vjoFRi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='linear', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='linear'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0DPSXLGPkpy",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33k-dpgBFeU7",
        "colab_type": "text"
      },
      "source": [
        "**4.5** меняем активационную функцию sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8sgAl2ZFoXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='sigmoid', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='sigmoid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbHIJF2qPoWa",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kMwn4LtFo99",
        "colab_type": "text"
      },
      "source": [
        "**4.6** меняем шаг обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5CHavhGF5-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-3\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRTMCIttPqs4",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi8sQIUeF6r6",
        "colab_type": "text"
      },
      "source": [
        "**4.7** меняем размер батча."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkv92AbBGF5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=40,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKOeYD6WPsyE",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMWOk785GGnB",
        "colab_type": "text"
      },
      "source": [
        "**4.8**  меняем число нейронов НС, увеличиваем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsCw2nkzIURU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(4500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUeiEthJPu01",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293pqxTcIVdK",
        "colab_type": "text"
      },
      "source": [
        "**4.9** меняем число нейронов НС, уменьшаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNnRzVvuIe1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtnpf8x0Pybj",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5duc8hg6Ivpv",
        "colab_type": "text"
      },
      "source": [
        "**4.11** меняем число слоев НС, уменьшаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0INWnvjEN0_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(2500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmaCX5R6P0ap",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gu3Wa44Ifc7",
        "colab_type": "text"
      },
      "source": [
        "**4.10** меняем число слоев НС, увеличиваем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGHyD8nmIvGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Создаём сеть \n",
        "model = Sequential()\n",
        "model.add(Dense(4500, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3500, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2500, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "#Указываем прямо шаг обучения - 1е-6\n",
        "model.compile(optimizer=Adam(lr=0.000001), loss='mse')\n",
        "\n",
        "#60000 примеров будет в обучающей выборке\n",
        "n_val = 60000\n",
        "history = model.fit(x_train[:n_val], \n",
        "                    y_train_scaled[:n_val],\n",
        "                    batch_size=20,\n",
        "                    epochs=30, \n",
        "                    validation_data=(x_train[n_val:], y_train_scaled[n_val:]), \n",
        "                    verbose=1)\n",
        "\n",
        "#Отображаем графики ошибки обучения на всех эпохах\n",
        "#Один по обучающей выборке, второй по проверочной\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Предсказываем проверочную выборку\n",
        "predict = model.predict(x_train[n_val:])\n",
        "#Меняем масштаб обратно от нормированного к оригинальному\n",
        "predict = y_scaler.inverse_transform(predict).flatten()\n",
        "\n",
        "#Считаем ошибку и модуль ошибки прогнозирования по всем примерам\n",
        "delta = predict - y_train[n_val:]\n",
        "abs_delta = abs(delta)\n",
        "\n",
        "#Считаем среднюю цену, среднюю ошибку и средни процени ошибки\n",
        "#Выводим на экран\n",
        "mean_delta = sum(abs_delta)/len(abs_delta)\n",
        "mean_price = sum(y_train[n_val:])/len(y_train[n_val:])\n",
        "print(\"Средняя ошибка: \", round(mean_delta))\n",
        "print(\"Средняя цена: \", round(mean_price))\n",
        "print(\"Процент ошибки: \", round(100*mean_delta / mean_price), \"%\", sep=\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJqX0p4LPPi3",
        "colab_type": "text"
      },
      "source": [
        "**ВЫВОД**"
      ]
    }
  ]
}